<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://xiwan.github.io</id>
    <title>Keep Thinking</title>
    <updated>2020-01-06T08:11:10.572Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://xiwan.github.io"/>
    <link rel="self" href="https://xiwan.github.io/atom.xml"/>
    <subtitle>有美人兮心不怿</subtitle>
    <logo>https://xiwan.github.io/images/avatar.png</logo>
    <icon>https://xiwan.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Keep Thinking</rights>
    <entry>
        <title type="html"><![CDATA[elk的fileds被撑爆了。。。]]></title>
        <id>https://xiwan.github.io/post/WBe1HiDrr</id>
        <link href="https://xiwan.github.io/post/WBe1HiDrr">
        </link>
        <updated>2020-01-06T07:41:25.000Z</updated>
        <summary type="html"><![CDATA[<p>今天调查了一个奇怪的问题，在其他日志都是看起来的情况下，突然发现某个日志在5号凌晨开始后没有被收录了。</p>
]]></summary>
        <content type="html"><![CDATA[<p>今天调查了一个奇怪的问题，在其他日志都是看起来的情况下，突然发现某个日志在5号凌晨开始后没有被收录了。</p>
<!-- more -->
<p>通过调查日志文件本身发现是有记录的，但是没有进入elk。由于前面我已经加上了日志counter和服务器id，那么可以排除日志hash碰撞的可能性。于是开始调查logstash，得到的日志结果:</p>
<p><strong>[2020-01-06T05:47:02,707][WARN ][logstash.outputs.elasticsearch] Could not index event to Elasticsearch. {:status=&gt;400, :action=&gt;[&quot;index&quot;, {:_id=&gt;&quot;f5a3e882bfcb4f155c99db18c07093e2&quot;, :_index=&gt;&quot;kakiraid-info-2020.01.06&quot;, :_type=&gt;&quot;kakiraid_log&quot;, :_routing=&gt;nil}, #<a href="LogStash::Event:0x2ccdcf00">LogStash::Event:0x2ccdcf00</a>], :response=&gt;{&quot;index&quot;=&gt;{&quot;_index&quot;=&gt;&quot;kakiraid-info-2020.01.06&quot;, &quot;_type&quot;=&gt;&quot;kakiraid_log&quot;, &quot;_id&quot;=&gt;&quot;f5a3e882bfcb4f155c99db18c07093e2&quot;, &quot;status&quot;=&gt;400, &quot;error&quot;=&gt;{&quot;type&quot;=&gt;&quot;illegal_argument_exception&quot;, &quot;reason&quot;=&gt;&quot;Limit of total fields [1000] in index [kakiraid-info-2020.01.06] has been exceeded&quot;}}}}</strong></p>
<p>原来是索引中的字段给撑爆了。联系起前几天调整的复杂日志结构问题，是有这个可能性的。因为为了分析开卡日志和减少日志放大倍数，为每个item都动态生成了field。没想到在这里给自己挖坑了。</p>
<p>好吧，调整下settings。这里最重要的就是这句&quot;index.mapping.total_fields.limit&quot;: 2000(默认值是1000)。当然这里需要考虑下对于开卡这种日志，其实有必要让他自己单独享用一个index，来减少这种问题。</p>
<pre><code>{
    &quot;index.indexing.slowlog.threshold.index.debug&quot; : &quot;2s&quot;,
    &quot;index.indexing.slowlog.threshold.index.info&quot; : &quot;5s&quot;,
    &quot;index.indexing.slowlog.threshold.index.trace&quot; : &quot;500ms&quot;,
    &quot;index.indexing.slowlog.threshold.index.warn&quot; : &quot;10s&quot;,
    &quot;index.mapping.total_fields.limit&quot;: 2000,
    &quot;index.merge.policy.max_merged_segment&quot; : &quot;5gb&quot;,
    &quot;index.merge.policy.segments_per_tier&quot; : &quot;24&quot;,
    &quot;index.number_of_replicas&quot; : &quot;1&quot;,
    &quot;index.optimize_auto_generated_id&quot; : &quot;true&quot;,
    &quot;index.refresh_interval&quot; : &quot;60s&quot;,
    &quot;index.routing.allocation.total_shards_per_node&quot; : &quot;-1&quot;,
    &quot;index.search.slowlog.threshold.fetch.debug&quot; : &quot;500ms&quot;,
    &quot;index.search.slowlog.threshold.fetch.info&quot; : &quot;800ms&quot;,
    &quot;index.search.slowlog.threshold.fetch.trace&quot; : &quot;200ms&quot;,
    &quot;index.search.slowlog.threshold.fetch.warn&quot; : &quot;1s&quot;,
    &quot;index.search.slowlog.threshold.query.debug&quot; : &quot;2s&quot;,
    &quot;index.search.slowlog.threshold.query.info&quot; : &quot;5s&quot;,
    &quot;index.search.slowlog.threshold.query.trace&quot; : &quot;500ms&quot;,
    &quot;index.search.slowlog.threshold.query.warn&quot; : &quot;10s&quot;,
    &quot;index.translog.durability&quot; : &quot;async&quot;,
    &quot;index.translog.flush_threshold_size&quot; : &quot;5000mb&quot;,
    &quot;index.merge.scheduler.max_merge_count&quot; : 10,
    &quot;index.merge.scheduler.max_thread_count&quot; : 1,
	&quot;index.unassigned.node_left.delayed_timeout&quot; : &quot;7200m&quot;
}
</code></pre>
<p>其他的是我为了加快索引速度给的一些“调优”。比如refresh_interval这个默认值是1s，虽然看上去日志是所见即所得，但有的时候并不需要这么快。可以适当的延长这个值，让日志在file_cache中多呆一会儿再被可见。其实对于elk来说，文档可见其实只要缓存到了file_cache中即可，并不需要写入到硬盘。当然通过flush也是可以保证这点的，但是它的代价就是磁盘io。</p>
<h3 id="如何重新装载日志呢">如何重新装载日志呢？</h3>
<p>为了保证日志的完整性，肯定是需要重新index受到影响的日志。这个结合filebeat的inode特性，我们首先需要隔离开受到“错误”影响的日志，比如某个时间段之后的日志的索引都有问题。按照我的经验是截至到当天的前一天为好。因为隔天处理当天日志比较稳妥。隔离开的日志只要更换下inode，然后就可以做到不停机的情况下重新index了。比较稳妥的方案是可以删除掉已经存在Index, 然后找一个压力比较小的时候做以上的操作:)</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[logstash 如何处理复杂日志]]></title>
        <id>https://xiwan.github.io/post/6SadtR1zT</id>
        <link href="https://xiwan.github.io/post/6SadtR1zT">
        </link>
        <updated>2019-12-26T10:30:44.000Z</updated>
        <summary type="html"><![CDATA[<p>最近压测发现日志在抽奖接口会放大百倍，直接把10万长度的日志队列挤爆！</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近压测发现日志在抽奖接口会放大百倍，直接把10万长度的日志队列挤爆！</p>
<!-- more -->
<p>深入调查后发现，抽奖接口的逻辑是得到一个物品就会对应一条日志。然后经常用户会大量开卡包的情况下，会单次获得许多物品，这样照成了日志的放大。压测时候每次请求会产生261条日志！！！</p>
<p>第一个想到的解决方案是日志合并，在抽奖的最后再写一条日志。不过这带来新的挑战，日志的维度会增加。导致现阶段的分析方式都无法使用了。</p>
<p>举例来说，对于这样一条日志，它是以分隔符竖线来区别每个字段意思的：</p>
<pre><code>2019-12-24 23:59:59|9|116504|76561198271728609@STEAM|4|86|9|127|32|-1|4||10011|1462231
</code></pre>
<p>这样我们在logstash里面处理时候简单的split结果，然后按照位置即可获得字段的意思。一次抽卡有可能产生多条这样的日志，所以上面的处理方案就会合并成</p>
<pre><code>2019-12-26 17:11:29|9|10001889532|bot1234567890|0|16|1617,87|1504^1,1551^1,1536^1,1539^1,1511^1,1503^1,1533^1,1552^1,1535^1,1504^1,1505^1,1528^1,1542^1,1519^1,1533^1,1525^1,1502^1,1503^1,1503^1,1502^1,1534^1,1545^1,1502^1,1502^1,1502^1,1505^1,1526^1,1510^1,1503^1,1549^1,1531^1,1509^1,1501^1,1526^1,1551^1,1501^1,1530^1,1504^1,1551^1,1548^1,1513^1,1521^1,1554^1,1511^1,1526^1,1551^1,1508^1,1529^1,1514^1,1516^1,1536^1,1526^1,1528^1,1554^1,1526^1,1551^1,1524^1,1541^1,1536^1,1502^1,1539^1,1549^1,1505^1,1511^1,1504^1,1539^1,1501^1,1501^1,1529^1,1529^1,1503^1,1551^1,1509^1,1519^1,1541^1,1528^1,1514^1,1507^1,1548^1,1512^1,1534^1,1523^1,1501^1,1501^1,1503^1,1534^1,1538^1,1529^1,1505^1,1517^1,1531^1,1536^1,1505^1,1539^1,1547^1,1504^1,1540^1,1504^1,1551^1,1535^1,1505^1,1519^1,1518^1,1504^1,1526^1,1525^1,1504^1,1501^1,1550^1,1542^1,1529^1,1554^1,1509^1,1552^1,1554^1,1512^1,1501^1,1521^1,1515^1,1525^1,1535^1,1552^1,1510^1,1527^1,1507^1,1523^1,1516^1,1513^1,1538^1,1551^1,1502^1,1536^1,1501^1,1506^1,1533^1,1543^1,1527^1,1539^1,1521^1,1513^1,1540^1,1504^1,1503^1,1530^1,1549^1,1552^1,1545^1,1553^1,1501^1,1536^1,1533^1,1551^1,1511^1,1502^1,1502^1,1529^1,1536^1,1549^1,1508^1,1552^1,1503^1,1533^1,1540^1,1512^1,1524^1,1501^1,1541^1,1536^1,1505^1,1503^1,1528^1,1523^1,1551^1,1513^1,1504^1,1527^1,1539^1,1512^1,1551^1,1550^1,1552^1,1507^1,1528^1,1536^1,1552^1,1505^1,1552^1,1548^1,1530^1,1536^1,1523^1,1509^1,1541^1,1503^1,1503^1,1533^1,1505^1,1505^1,1508^1,1501^1,1535^1,1543^1,1508^1,1523^1,1536^1,1514^1,1542^1,1547^1,1505^1,1504^1,1539^1,1503^1,1503^1,1502^1,1551^1,1525^1,1545^1,1516^1,1522^1,1543^1,1552^1,1501^1,1503^1,1504^1,1532^1,1531^1,1505^1,1518^1,1536^1,1552^1,1501^1,1551^1,1509^1,1535^1,1520^1,1511^1,1539^1,1523^1,1514^1,1504^1,1546^1,1515^1,1504^1,1527^1,1529^1,1524^1,1547^1,1534^1,1548^1,1525^1,1501^1,1552^1,1547^1,1548^1,1527^1,1501^1,1551^1,1546^1,1504^1,1552^1,1547^1||10021|199
</code></pre>
<p>对的，你没看错也没有搞错！一下子日志维度就上去了。</p>
<h3 id="改造logstash">改造logstash</h3>
<p>由于单纯的写logstash的split似乎无法完成上面的任务了（主要问题是不定长array处理起来十分麻烦），所以我对准了它的ruby插件:</p>
<pre><code>ruby {
        code =&gt; '
          item_array=event.get(&quot;[log_json][t9_item_id]&quot;).split(&quot;,&quot;)
          event.set(&quot;[log_json][t9_item_length]&quot;, item_array.length)
          for item in item_array
            value=event.get(&quot;[log_json][t9_item_#{item.split(&quot;^&quot;)[0]}]&quot;)
            if value.nil?
              event.set(&quot;[log_json][t9_item_#{item.split(&quot;^&quot;)[0]}]&quot;, item.split(&quot;^&quot;)[1].to_i)
            elsif
              event.set(&quot;[log_json][t9_item_#{item.split(&quot;^&quot;)[0]}]&quot;, item.split(&quot;^&quot;)[1].to_i+value.to_i)
            end
          end
        '
      }
</code></pre>
<p>可以看到在ruby内部, 每一条日志其实是一个event. 通过内置的event.set 和 get方法就可以很简单的将日志继续分割下去。</p>
<p>最后得到的结果为：</p>
<figure data-type="image" tabindex="1"><img src="https://xiwan.github.io/post-images/1577357078972.png" alt=""></figure>
<p>当然我们也关系加入新的ruby插件后的效率问题。找了台4G，2核的普通机器在没有调优参数的情况下，pv 压测后的结果为:</p>
<p>4核4GB的机器结果** 978KiB 0:05:43 [2.85KiB/s]**差不多100万条复杂数据，每秒2.85k个event的速度</p>
<p>这里有个比较有意思的收获，原来获取array的尾部在conf里面可以写-1...</p>
<h3 id="elk查询">elk查询</h3>
<p>上面基本解决了logstash在多维度结构时候的解析问题，对于elk中一个按照物品id的聚合查询该如何做呢？</p>
<p>我想的思路是： 传入item_id, 匹配日志name, 由于value是记录了数目，那么query里面的条件则是Numeric Range Query Usage来进行比较（大于0即可）。在aggregator里面的则是用总和sum操作即可。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis 大key处理]]></title>
        <id>https://xiwan.github.io/post/b0uwzUXQ8</id>
        <link href="https://xiwan.github.io/post/b0uwzUXQ8">
        </link>
        <updated>2019-12-16T04:38:38.000Z</updated>
        <summary type="html"><![CDATA[<p>最近压测登陆接口，发现处理超过1k的byte对象（我们初始化就有3k,跑起来后可以达到40k）时候，整体的tqs下降得十分厉害。从一般几千得并发掉落倒了不到一千，还有不少得错误。<br>
<img src="https://xiwan.github.io/post-images/1576471294178.png" alt=""></p>
]]></summary>
        <content type="html"><![CDATA[<p>最近压测登陆接口，发现处理超过1k的byte对象（我们初始化就有3k,跑起来后可以达到40k）时候，整体的tqs下降得十分厉害。从一般几千得并发掉落倒了不到一千，还有不少得错误。<br>
<img src="https://xiwan.github.io/post-images/1576471294178.png" alt=""></p>
<!-- more -->
<p>经过调查这个应该是redis在处理大key时候的一个坑，每次的全量更新让单线程的redis十分缓慢，无法在规定时间内完成操作。</p>
<h2 id="解决办法">解决办法</h2>
<p>对于大key,网上查了下给了两种解决方案：</p>
<pre><code>1. 改成hash格式，每次更新hash的一个部分
2. 将大key改成多个小key的组合，使用multiSet,或者multiGet来完成业务。
</code></pre>
<p>这两种方案其实大同小异，但比较不爽的是需要对业务部分进行从新梳理。这样才可以控制每个部分的大小。改造方案其实是十分昂贵的。如果不是一开始就有考虑这个部分，其实不建议这么操作。</p>
<p>对于redis的key-value模型，value其实作为stream存储的话，我们可以采用一种另存整取的思路来做。比如每次我按照200Byte存一次，对于一个1KB的数据，我们需要存5条记录就可以了。相应的，在我们需要读取时候，我们把对应key所有的相关的key数据按照一定顺序还原就可以恢复成原来的对象了。</p>
<h3 id="零存方案">零存方案</h3>
<pre><code>        public async Task SegmentWrite(string key, byte[] data)
        {
            IByteBuffer bytesBuffer = Unpooled.Buffer(data.Length);
            try
            {
                // 加锁
                if (!await Lock(key))
                {
                    throw new Exception(&quot;Lock-fail &quot; + key);
                }

                IBatch batch = DB().CreateBatch();
                bytesBuffer.WriteBytes(data);
                int j = 0;
                while (bytesBuffer.ReadableBytes &gt; 0)
                {
                    var ReadableBytes = Math.Min(segmentLength, bytesBuffer.ReadableBytes);
                    var segKey = key + &quot;-&quot; + j++;
                    //await batch.StringAppendAsync(segKey, bytesBuffer.ReadBytes(ReadableBytes).Array, flags: CommandFlags.FireAndForget);
                    await batch.StringSetAsync(segKey, bytesBuffer.ReadBytes(ReadableBytes).Array, flags: CommandFlags.FireAndForget);
                }
                if (j&gt;0)
                    batch.Execute();

            }
            catch (Exception ex)
            {
                Console.WriteLine(ex.Message);
            }
            finally
            {
                bytesBuffer.Release();
                data = null;
                if (!await Unlock(key))
                {
                    throw new Exception(&quot;Unlock-fail&quot;);
                }
            }
        }
</code></pre>
<h4 id="整取方案">整取方案</h4>
<pre><code>        public async Task&lt;T&gt; SegmentRead&lt;T&gt;(String key)
        {
            IByteBuffer bytesBuffer = Unpooled.Buffer(segmentLength);
            try
            {
                if (!await Lock(key))
                {
                    throw new Exception(&quot;Lock-fail &quot; + key);
                }
                RedisResult keysResult = await DB().ExecuteAsync(&quot;keys&quot;, key + &quot;-*&quot;);
                if (keysResult.IsNull) {
                    return default;
                }
                RedisResult[] keyList = (RedisResult[])keysResult;

                List&lt;Task&gt; ayncTaskList = new List&lt;Task&gt;();
                foreach (var _key in keyList.OrderBy(k =&gt; Encoding.Default.GetString((byte[])k)).ToArray())
                {
                    var keystr = Encoding.Default.GetString((byte[])_key);
                    bytesBuffer.WriteBytes(await DB().StringGetAsync(keystr));
                }
                return bytesBuffer.ReadableBytes &gt; 0 ? bytesBuffer.ReadBytes(bytesBuffer.ReadableBytes).Array.Deserialize&lt;T&gt;() : default;
            }
            catch (Exception ex)
            {
                Console.WriteLine(ex.Message);
                return default;
            }
            finally
            {
                bytesBuffer.Release();
                if (!await Unlock(key))
                {
                    throw new Exception(&quot;Unlock-fail&quot;);
                }

            }

        }
</code></pre>
<h3 id="注意事项">注意事项</h3>
<ol>
<li>由于对于大key单次的写入和读取操作都被分割成了小块，所以redis的原子操作已经被破坏。所以我们每次写之前对于同一个key要加锁，写完之后再释放锁。同理，在读的时候也要检查是否有写的锁，如果某个进程正在写入同一个key，则需要等待。</li>
<li>等待不能无止境的持续下去，要做好保护，防止程序卡死。</li>
<li>对于切割出来的基本单元可以采用pipeline写入方式保证效率</li>
<li>读取key的时候一定要做好排序，保证结果的正确性。</li>
<li>不能将基本单元切割得过小，产生的key过多也会成为性能瓶颈。</li>
<li>减少内存拷贝</li>
</ol>
<h3 id="测试结果">测试结果</h3>
<p>在500B为一个基本单元情况下的测试结果。可以看到错误率明显下降，整体的tqs也上升了20%左右。<br>
<img src="https://xiwan.github.io/post-images/1576472238470.png" alt=""></p>
<p>观察了下elk的做法，它也会将index拆分成5个shard，然后做一份replica，再散列在集群里面。这么做的好处是可以减少某个热key引起的请求偏移；当然也不需要再关注上层的业务逻辑了。这应该是一个比较主流的做法：</p>
<figure data-type="image" tabindex="1"><img src="https://xiwan.github.io/post-images/1577268824992.png" alt=""></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[filebeat踩坑inode]]></title>
        <id>https://xiwan.github.io/post/filebeat踩坑inode</id>
        <link href="https://xiwan.github.io/post/filebeat踩坑inode">
        </link>
        <updated>2019-11-18T07:39:13.000Z</updated>
        <summary type="html"><![CDATA[<p>最近我们游戏调整了服务器架构，所以涉及到一些文件系统的改动。类似于文件重命名之类。按照之前的理解这种操作在停服时候做，通过脚本应该是比较安全快捷的。不过正式由于这个操作，让我花了一个通宵才查明一个filebeat的问题。</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近我们游戏调整了服务器架构，所以涉及到一些文件系统的改动。类似于文件重命名之类。按照之前的理解这种操作在停服时候做，通过脚本应该是比较安全快捷的。不过正式由于这个操作，让我花了一个通宵才查明一个filebeat的问题。</p>
<!-- more -->
<h2 id="表现">表现</h2>
<p>说到具体表现就是重启服务器后，发现ELK收集日志部分Load十分高。排查下来发现filebeat重新在收集已经收集过的日志。对于日志量少的服务器这个变化应该是很难察觉的。但不巧的是，我们玩家服务器已经积累了几亿的日志，集群的速度估计3kw-5kw之间。这么算下来，我们至少有一个礼拜没法看日志了。</p>
<p>反复检查完配置，也确认了registery没有被误删除的情况下，怎么filebeat会突然抽风。不认识已经收集过的日志了？思来想去，只能硬着头皮查Registry相关信息：</p>
<h3 id="registry文件">Registry文件</h3>
<p>Filebeat会将自己处理日志文件的进度信息写入到registry文件中，以保证filebeat在重启之后能够接着处理未处理过的数据，而无需从头开始</p>
<p>registry文件内容为一个list，list里的每个元素都是一个字典，字典的格式如下：</p>
<pre><code>source： 记录采集日志的完整路径
offset： 采集这个日志文件到了哪个位置，总采集字节数
inode： 日志文件的inode号，关于inode的详细解释看下文
device： 日志所在的磁盘编号，下文stat命令中Device的值
timestamp： 日志最后一次发生变化的时间戳
ttl： 采集失效时间，-1表示永不失效
</code></pre>
<p>Filebeat在每次启动时都会来读取这个文件，如果文件不存在则会创建新文件。</p>
<h3 id="inode解释">inode解释</h3>
<p>那么Filebeat是怎么判断一个文件是否认识呢？原来它是基于inode这个字段。可以说这个是linux文件系统的一个比较核心的东西。它这个结构体定义了一系列文件的元信息，比如文件的创建者、创建时间、文件大小等等。每个文件都对应了它，一般可以用 <strong>stat</strong> 命令查看。</p>
<p>简单理解就是在linux中，同一个文件的判断条件就是inode值是否相等。如果要快速查看inode，可以用 <strong>ls -i</strong>命令看到这里，我有了一个推断：这次调整结构为了脚本的方便调整了日志的路径。但是具体的脚本是用cp方式建立的。cp方式虽然会让文件的内容和名字一致，但是会去重新申请inode值。当然如果系统的inode值耗尽了，尽管还有磁盘空间，也会导致无法建立新的文件。如果要保持inode不变，需要用的是mv方式或者ln（硬链接，不是软连接）方式，并且不能跨磁盘（区）。</p>
<h2 id="验证">验证</h2>
<p>估计filebeat底层也是沿用的这一套。为了验证我的猜想，于是做了下面的实验：</p>
<figure data-type="image" tabindex="1"><img src="https://xiwan.github.io/post-images/1574064453379.png" alt=""></figure>
<p>可以看到同一个文件通过cp方式，inode值的确变化了。相应的我们用mv方式就不会有影响：</p>
<figure data-type="image" tabindex="2"><img src="https://xiwan.github.io/post-images/1574064532919.png" alt=""></figure>
<p>网上也查到filebeat的文件说明：</p>
<figure data-type="image" tabindex="3"><img src="https://xiwan.github.io/post-images/1574064603448.png" alt=""></figure>
<h2 id="解决">解决</h2>
<p>到这里，自然解决方案也出来了</p>
<pre><code>1. 写脚本用mv的方式来移动老的日志文件
2. 不要随意改变既定的文件结构
</code></pre>
<p>操作完之后，果然filebeat又重新识别出来老的日志文件了。整个elk的压力也下去了。回过头看这一次踩坑：感觉linux底层还是值得好好研究下的。写写脚本简单，但也只是知其然不知其所以然。对于cp，mv, rm这类常用命令的理解也深刻了不少。自己操作或者指导别人时候也会特别小心了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[写代码的一点思考]]></title>
        <id>https://xiwan.github.io/post/写代码的一点思考</id>
        <link href="https://xiwan.github.io/post/写代码的一点思考">
        </link>
        <updated>2019-11-07T04:22:58.000Z</updated>
        <summary type="html"><![CDATA[<p>专门用来总结一些经验和想法，不一定正确</p>
]]></summary>
        <content type="html"><![CDATA[<p>专门用来总结一些经验和想法，不一定正确</p>
<!-- more -->
<h2 id="利用反射和泛型快速创造一个对象">利用反射和泛型快速创造一个对象</h2>
<p>这里可以看到一个Single类的写法<br>
<img src="https://xiwan.github.io/post-images/1573101268759.png" alt=""></p>
<p>那么当我们需要让另外一个类成为单例时候就可以很简单的继承它即可</p>
<pre><code>    public class Director : Single&lt;Director&gt;
</code></pre>
<p>这个写法只是适合部分场景，对于对于常用的Helper类，其实直接用static类就可以了。</p>
<h2 id="通过多重继承来继承多个类">通过多重继承来继承多个类</h2>
<p>一般来说单个类都是无法一次性继承多个类的，但是我们可以让这类之间行成父子关系。这样最终的儿子类是可以拥有所有先辈的公共成员的。</p>
<p>我们创建了一个抽象类继承了Single，则它拥有了单例的特性</p>
<pre><code>    public abstract class SheetObj&lt;T, V&gt; : Single&lt;T&gt; 
        where T: class where V : ExtendObj
</code></pre>
<p>然后又创建了三个子类继承了SheetObj</p>
<pre><code>    public class EnumBook : SheetObj&lt;EnumBook, Enum&gt;
    public class RangeBook : SheetObj&lt;RangeBook, Range&gt;
    public class EnumBook : SheetObj&lt;EnumBook, Enum&gt;
</code></pre>
<p>那么我们在使用这些子类时候就可以这么用：</p>
<pre><code>// Single类的初始化方法
    RangeBook.Initialize();
    EnumBook.Initialize();
    TreeBook.Initialize();
// SheetObj的加载数据方法
    RangeBook.Instance.Load(MasterDataFilePath);
    EnumBook.Instance.Load(MasterDataFilePath);
    TreeBook.Instance.Load(MasterDataFilePath);
</code></pre>
<p>实际上使用时候还可以考虑抽象函数，虚函数或者协议接口之类来满足自己的需求。</p>
<h2 id="抽取共同的成员到基类">抽取共同的成员到基类</h2>
<p>比如类A,B,C都有一个成员变量为ID，那么就可以先做一个基类，其余的类可以通过继承方式获取到这个成员变量。当然，这个思路可以扩展开来，会让类的结构有些复杂。但是能节省很多重复劳动工作。<br>
不过有些项目不在乎这些重复，希望简单直白的类来节约debug时间。所以真正如何使用还是需要权衡。</p>
<p>不过现在很多代码插件都有一键生成各种set, get方法。甚至还有比较邪门的lombook这类东西。底层似乎是用了动态类的机制。在这里就不展开了。</p>
<h2 id="覆盖object的tostring方法">覆盖object的ToString()方法</h2>
<p>在基类中重写ToString()方法，这样可以在Debug问题时候十分方便的查看对象的具体数据。</p>
<figure data-type="image" tabindex="1"><img src="https://xiwan.github.io/post-images/1573102105886.png" alt=""></figure>
<h2 id="善用builder模式">善用Builder模式</h2>
<p>经常写代码时候会碰到要创建一个对象块，由于成员变量过多，会导致代码块十分臃肿。这个时候可以用Builder模式来改造类。</p>
<figure data-type="image" tabindex="2"><img src="https://xiwan.github.io/post-images/1573102260623.png" alt=""></figure>
<p>上图这个列子中p1和p2就是很好解释了前面的观点。<br>
p2是一种普通的生成类的方式，十分简单直白，但不好的是业务逻辑和生命混杂在一起十分乱。p1比较起来就会显得简单很多。</p>
<p>通常的思路是创建一个Builder类专门负责生成目标对象。这么做的好处主要是如下考虑<br>
1. 在生成对象的地方代码会十分简洁，配合链式声明，整个代码的可读性也会很好。<br>
2. 解耦了对象生成和具体的业务逻辑，对调用者保持透明性。</p>
<p>不过正如第二点说明那样，业务逻辑被挪到了Builder里面去做了，这并不会少写不少代码。不过就我个人来说，目前还是比较值的。</p>
<figure data-type="image" tabindex="3"><img src="https://xiwan.github.io/post-images/1573102774966.png" alt=""></figure>
<h2 id="builder继续优化">Builder继续优化</h2>
<p>通过观察发现这些设置成员变量的方法似乎都是差不多模式：通过一个key算出一个值，然后赋予成员便令，最后返回Builder本身。这样我们可以使用delegate模式，把这个部分的逻辑通过方法参数传入进来。</p>
<figure data-type="image" tabindex="4"><img src="https://xiwan.github.io/post-images/1573114364942.png" alt=""></figure>
<p>这样我们的Builder就会变得十分轻量了，前面所有的赋值操作以及返回都变作了一个delegate函数：</p>
<figure data-type="image" tabindex="5"><img src="https://xiwan.github.io/post-images/1573114497904.png" alt=""></figure>
<p>这样我们使用Builder生成对象也有相应变化：</p>
<figure data-type="image" tabindex="6"><img src="https://xiwan.github.io/post-images/1573114673344.png" alt=""></figure>
<p>如上图所示，我们发现p3和p1比较起来似乎更加复杂了，也不如p2直观。 其实这一来一去，我们从p2模式到p1主要是为了解决代码块比较笨重的问题，扩展性也差。但是新的问题是业务逻辑被隐藏到了Builder里面。其实仔细想想，对于Builder来说它并不需要关心你业务逻辑是怎样的，它唯一要做的就是把某个业务逻辑（规则）产生的结果赋予给相应的值就好了。基于这个考虑，我们也要把业务逻辑解耦开来。所以通过delegate这种方式，很好地做到了这点。整个builder赋值时候做地也是最存粹地操作而已！</p>
<p>p3的做法把这也业务规则包装成方法后，可以写一个专门地处理业务逻辑类，它负责封装各种业务算法然后输出而已。同样也保持了简单高效的模式。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[steam真的挂了2小时]]></title>
        <id>https://xiwan.github.io/post/steam真的挂了2小时</id>
        <link href="https://xiwan.github.io/post/steam真的挂了2小时">
        </link>
        <updated>2019-10-29T07:30:59.000Z</updated>
        <content type="html"><![CDATA[<p>早上一起来被告知昨晚有将近两个小时的游戏服务器连接失败。大概的样子是这样：</p>
<figure data-type="image" tabindex="1"><img src="https://xiwan.github.io/post-images/1572334369507.png" alt=""></figure>
<p>第一排查的是机房网络情况，经过询问得知网络正常。然后开始分析日志，发现如下特点：</p>
<ol>
<li>连接失败的开始时间和结束时间差不多（夜里2点-4点）</li>
<li>两个机房都出现了上面的情况（国内，国外）</li>
</ol>
<p>根据以上两条进一步分析，机房的网络问题被排除了。</p>
<p>排除掉机房后，我又看了下当时的cpu内存情况也没有异常。接下来只能重新掉头分析上报内容了，感觉大部分失败都是在登陆界面。游戏内玩家报告失败的情况没有。这个时候反应是不是steam平台炸了。但是这个怎么验证呢？这么大的平台炸了，为啥网上没有一点消息。。。</p>
<p>接着只能硬着头皮查日志了</p>
<figure data-type="image" tabindex="2"><img src="https://xiwan.github.io/post-images/1572334817578.png" alt=""></figure>
<p>根据日志这段时间分析也发现了几个特点：</p>
<pre><code>1. 两个机房出现情况的时间点不单单是差不多，而是精确到秒级别的同步。
2. 一般的超时差不多就是几百毫秒，这段时间的超时居然高达了100秒。
</code></pre>
<p>根据1来推断有两种可能性。第一种是我们又被攻击了，不过我很快否定了这个想法。因为攻击不可能挑选半夜人少时候，并且只持续了2小时左右就停止了，这个不大符合规律。那么就是最不可能的肯能了：steam平台昨晚挂了。</p>
<p>steam平台有波动是很正常，但2个小时的时间算是一个不小的事故了。会不会是因为某次波动导致的底层bug，从而请求阻塞之类？不过经过老板提点，还是否定了这个思路，因为两个机房，相同的时间节点。由于两边环境的差异，不可能这么凑巧的。所以真相只有一个：steam 挂了2小时。</p>
<p>顺着这个思路，我终于找到了一个作证：</p>
<figure data-type="image" tabindex="3"><img src="https://xiwan.github.io/post-images/1572335271678.png" alt=""></figure>
<p>相关网站 https://outage.report/steam 。这个是一个专门给玩家们上报steam 挂机了的网站。报告的热点图几乎都在北美和欧洲，国内似乎知道的人很少，并且由于出问题时间在半夜，所以并没有人会怀疑到steam上面去。</p>
<p>这下一切就解释得通了：steam昨晚真得挂了2个小时！根据宕机历史来看，steam不算太靠谱。。。</p>
<h2 id="隐患">隐患</h2>
<p>当解决完上面的疑惑后，还有一个问题：为啥steam宕机时候我们居然挂机了100秒？幸亏这个问题是半夜发生，如果是高峰期，可能直接导致游戏内玩家都会无法使用。这也算是一个比较大的隐患了。当然，最后解决这个问题是比较简单，重新设置下timeout和readwritetimeout时间就好了。</p>
<p>对于request里面给的解释：</p>
<pre><code>timeout 相当于请求发出到建立连接所花费的时间，默认100秒
readwritetimeout 相当于建立连接到下载完整个包体需要的时间，默认300秒
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[最近...]]></title>
        <id>https://xiwan.github.io/post/最近</id>
        <link href="https://xiwan.github.io/post/最近">
        </link>
        <updated>2019-10-11T07:58:54.000Z</updated>
        <summary type="html"><![CDATA[<p>这一个月经过努力好不容易把我们的游戏送上了steam。中间踩了不少坑，无数次的加班才换来的结果。当然现在回国头去看一切还是挺值的。游戏在没有任何推广情况下，口碑和数据都保持得不错。每天在留言板和q群里面看玩家和我们的互动也慢慢成为我得日常部分。今天好不容易闲下来了一点，对过去一段时间做个回顾看看</p>
]]></summary>
        <content type="html"><![CDATA[<p>这一个月经过努力好不容易把我们的游戏送上了steam。中间踩了不少坑，无数次的加班才换来的结果。当然现在回国头去看一切还是挺值的。游戏在没有任何推广情况下，口碑和数据都保持得不错。每天在留言板和q群里面看玩家和我们的互动也慢慢成为我得日常部分。今天好不容易闲下来了一点，对过去一段时间做个回顾看看</p>
<!-- more -->
<h2 id="游戏方面">游戏方面</h2>
<p>首先steam这个平台对于我们这种小团队来说是当前来说比较好的选择。由于大环境的影响，手游的排期一直在等消息。投资人也是急于将我们游戏变现一部分来度过寒冬。前面3次测试我们还算是稳扎稳打，手机上数据不算经验但也能交代。中途突然说我们改方向去PC，其实团队还是很担忧的。毕竟PC的玩家和手机并不能算完全重合的一波人。需要为PC做很多改动，让它看起来不是那么的手游。玩法上的调整也是一个挑战。</p>
<p>总的说来就是时间紧任务急。这段时间团队不少人996来赶进度。当然老板也是挺拼的一人，这里要着重说下，几乎所有的游戏玩法和服务器逻辑部分都是他在搞。那么我在干嘛？哈哈哈。我现在算是这个小团队的技术负责人，是在做很多看不见的部分，游戏底层的架构，高并发，日志收集分析和运维自动化之类，当然包括很多团队都头疼的平台接入。小公司并没有特别富裕的人手，并且很多人还良莠不齐。所以这些东西都需要我自己来搞。</p>
<p>大概讲下我的一些做法吧。</p>
<h3 id="底层部分">底层部分</h3>
<p>这边游戏底子是C#写的，方便前后端公用些公共库。但不好是老板写这些东西时候都是东平西凑加上自己的积累写的一套底层协议。只是看上去可以用而已，经常会出现一些诡异的问题。比如第一次测试就发现服务器经常不响应，然后得手动重启机器。不过好在老板本身还是认识到了这个问题，并没有执着于过去得经验。我过来的第一件事情就是整理这个部分。</p>
<p>自己认为经验还是可以，所以先自己是用jmeter做了套压测系统来做各种关键接口的评测。后面又找了dotnetty来替换底层进行新的一轮压测。用数据说话来证明野路子只是能用，但没法长久用。当然这个部分也是前前后后搞了我一个多月才完成。事实证明这个替换是值得的，在我们第三次测试时候我们就顺利抗住了大量玩家的请求。</p>
<p>当然对于一些中间件的使用我还是比较有话语权的，尤其是redis部分。感觉刚开始老板的用法都是极其粗暴简单，基本就是用下hash, string之类，复杂的结构几乎不触及。处于一个知其然但不知其所以然的状态。这都是小团队的痛楚。反正就是这么一点点磨啊磨，现在也开始有点像模像样了吧。</p>
<p>总结下来：如果你不是天才，请不要相信自己造轮子的能力，因为前路崎岖且慢慢。</p>
<h3 id="日志部分">日志部分</h3>
<p>同样老的做法是记录好日志后，导入mysql，然后写各种查询。但同样由于不深入研究这个东西得化，没法抗住海量日志的。我一开始也是挠头，幸好在前面公司有看他们使用过ELK。于是就硬着头皮啃下来了这个部分。现在回头看，从最简单的demo跑通，到现在做到了集群分布。这中间的坑也是踩了不少。比如原来日志格式在logstash中需要自己手动写分析规则，elasticsearch那些恶心的查询语句，当然少不了调优参数时候各种痛苦。</p>
<p>现在出来的效果还是不错的，团队成员也基本适应了如何进行简单检索，我们也抗过了亿级别的日志流量。当然我自己也很习惯在上面做二次开发，做各种维度的日志分析了。</p>
<h3 id="自动化">自动化</h3>
<p>这个其实也是慢慢发现的。刚开始我需要去接一个渠道的包，然后这个手动过程异常恶心。通常打一个包需要一个多小时。当然以前我就知道这个东西恶心了，之前的团队我并不需要搞，而是由专门的“包王”来处理。</p>
<p>作为程序的我，干了几次就不舒服了。这lifestyle也太差了！幸好我对于脚本还比较在行，由于大环境我们也是从windows往linux转，所以我索性开始用脚本记录自己的操作步骤了。接着慢慢又引入了jenkins这个东西，一切都顺理成章的这么发生了。现在团队的前台后台所有的程序包都通过自动化来控制，无疑大大地解放了生产力。我现在要做地也只是教会他们如何选择下拉框而已。</p>
<p>在做自动化过程中我还培养了出来一个算可以的运维人员，从linux不懂，到现在也能产出不少脚本了。自然也解放了我不少的精力。同时也不用我半夜起来对接运营了。</p>
<p>自动化其实是一种体系，并不是一个脚本两个脚本就算自动化了。简单脚本其实是只能算小工具的。这中间需要吃透管理，架构，甚至一些人性来做。我自己也算是摸索到了一些思路。以后倒可以开篇说。</p>
<h3 id="测试">测试</h3>
<p>这也是一个项目能否走远的重要保障。但小团队往往都是最后一天才交货，认为自己写完了就算功能完了，甚至连基本的自测都没有。随便使用一个小的bug工具就算有管理了。感觉就是有点自欺欺人吧。我来这边后显示把后台重要接口都压测一遍，然后对于前端的要求就是：重要的基础功能要自己写用例自己来测试，并且我都会盯着看。因为越是那些底层的越容易忽视，比如偶尔出现的连不上去啊，或者网络交互的不稳定啊。其实总结下来：就是测试不到位，自己很多逻辑上的漏洞都没有发现。为了改变这个现状，我把重要的基础功能都用showdoc清楚的设计出来，用例也严格按照这个写。终于前面2测发现的很多制命问题，在第三测都没有了。也算是长须了一口气。</p>
<h3 id="管理">管理</h3>
<p>这个部分对于一直写代码的我来说并不是特别在行。我也会套用一些敏捷的原则，指定主从分支，版本号管理，提交节点之类的东西。但怎么说呢？效果不好。尤其是在小团队上面，人员精神面貌和积极性就摆在那里。这个东西关键靠的是执行。所以一旦碰上点业务忙就容易把之前的节奏打乱。我还是属于那种比较佛系思维的人，所以干了一阵子还是去找了专业项目经理来比较好。</p>
<h2 id="总结">总结</h2>
<p>写了一大通，感觉有点牢骚表现。毕竟自己当初脑子一热从明星上市企业出来，追求自己的游戏梦吧。结果这一年多下来做的还是更偏底层的东西了。中间有一段时间我自己还是有些执念。自己会学习Unity之类的东西，写各种最后无疾而终的小游戏。可能还是有想法哪天自己可以写写酷炫的前端吧（应该没啥问题😁）</p>
<p>反正就这么过来了，现在游戏的上线，更感觉是自己是幕后的扫地僧。虽然感觉不出来游戏中的贡献，但正如老板说的：没我这游戏出不来。。。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker 日志处理]]></title>
        <id>https://xiwan.github.io/post/docker 日志处理</id>
        <link href="https://xiwan.github.io/post/docker 日志处理">
        </link>
        <updated>2019-09-18T03:59:22.000Z</updated>
        <summary type="html"><![CDATA[<p>docker 启动后有一个需求便是如何处理以及收集它产生的日志。<br>
这里的日志可以分为3类： docker的引擎日志， docker 容器日志， docker 应用日志</p>
]]></summary>
        <content type="html"><![CDATA[<p>docker 启动后有一个需求便是如何处理以及收集它产生的日志。<br>
这里的日志可以分为3类： docker的引擎日志， docker 容器日志， docker 应用日志</p>
<!-- more -->
<h3 id="docker-引擎日志">docker 引擎日志</h3>
<p>这个查找了写文章后总结如下，根据自己对应的系统去查找即可</p>
<p><strong>Ubuntu(14.04)</strong>	/var/log/upstart/docker.log<br>
<strong>Ubuntu(16.04)</strong>	journalctl -u docker.service<br>
<strong>CentOS 7/RHEL 7/Fedora</strong>	journalctl -u docker.service<br>
<strong>CoreOS</strong>	journalctl -u docker.service<br>
<strong>OpenSuSE</strong>	journalctl -u docker.service<br>
<strong>OSX</strong>	~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/log/d‌​ocker.log<br>
<strong>Debian GNU/Linux 7</strong>	/var/log/daemon.log<br>
<strong>Debian GNU/Linux 8</strong>	journalctl -u docker.service<br>
<strong>Boot2Docker</strong>	/var/log/docker.log</p>
<h3 id="docker-容器日志">docker 容器日志</h3>
<p>容器的日志 则可以通过 docker logs 命令来访问，而且可以像 tail -f 一样，使用 docker logs -f 来实时查看。如果使用 Docker Compose，则可以通过 docker-compose logs &lt;服务名&gt; 来查看。</p>
<p>如果需要查看容器日志的具体位置可以调用命令：<br>
<img src="https://xiwan.github.io/post-images/1568779631501.png" alt=""></p>
<p>可以看到这个是一个非常复杂的路径，每次看这个文件是非常不方便的。比较好的解决方案是用一个日志收集器来收集这些日志，比如利用<a href="https://tonybai.com/2016/03/25/ship-docker-container-log-with-filebeat/">filebeat</a>来收集日志，然后集中到ES中查询。不过需要一些软件安装或者配置。</p>
<p>这里我使用一个比较简单的方案， 利用docker-compose 的logs命令将对应service输出到默认的位置。这样不用担心频繁的up down导致的容器号变化。</p>
<pre><code>nohup docker-compose -f docker-compose-esk.yml logs -f kibana &gt;&gt; /data/game/logs/elk/VM_18_7_centos-kibana.log &amp;
</code></pre>
<p>当然，不同机器上的日志可以通过定时rsync命令拉取到同一台机器方便查找。</p>
<h3 id="docker应用日志">docker应用日志</h3>
<p>由于docker是无状态的，可以通过volums来实现和宿主机的互通。我们可以将docker内应用日志和数据方便地放在宿主机管理，比较简单。可以同时在宿主机上启动一个filebeat将日志发送到内部es机器即可。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[dota如何接入支付]]></title>
        <id>https://xiwan.github.io/post/dota如何接入支付</id>
        <link href="https://xiwan.github.io/post/dota如何接入支付">
        </link>
        <updated>2019-09-04T07:41:37.000Z</updated>
        <summary type="html"><![CDATA[<p>对于自定地图来说，接入支付应该是比不可少的步骤。这里主要以支付宝为例子来说明下大概流程</p>
]]></summary>
        <content type="html"><![CDATA[<p>对于自定地图来说，接入支付应该是比不可少的步骤。这里主要以支付宝为例子来说明下大概流程</p>
<!-- more -->
<h3 id="主体流程">主体流程</h3>
<figure data-type="image" tabindex="1"><img src="https://xiwan.github.io/post-images/1567582907291.png" alt=""></figure>
<h4 id="预支付部分">预支付部分</h4>
<ol>
<li>ui界面发起向lua服务器的支付请求，同时监听支付返回事件。</li>
<li>lua服务器调用游戏服务器支付api，这里一般使用的是CreateHTTPRequestScriptVM 方法来拉起http请求。具体用法建议参考其他项目。</li>
<li>游戏服务器接入好支付sdk后，通过sdk的api拉起预支付请求（如何配置可以参考网上很多例子）。如果是java的服务器代码，就调用 AlipayTradePrecreateRequest 接口就好了。同时也可以在这里完成创建订单的操作。</li>
<li>同步等待平台预支付结果。</li>
<li>这里可以根据返回结果来做一些数据更新的操作。然后将二维码地址告知lua服务器端。</li>
<li>lua服务器获取到预支付的结果，告知ui界面展示二维码。</li>
</ol>
<h4 id="支付部分">支付部分</h4>
<ol start="7">
<li>客户扫描二维码，与平台交互支付过程。</li>
<li>支付成功后，平台返回结果给客户</li>
<li>同时，平台会异步告知交易结果给游戏服务器。游戏服务器继续完成数据更新操作。</li>
<li>似乎没啥用。</li>
</ol>
<h4 id="测试结果">测试结果</h4>
<figure data-type="image" tabindex="2"><img src="https://xiwan.github.io/post-images/1567582911160.png" alt=""></figure>
<h4 id="注意">注意</h4>
<p>如果使用沙箱环境，要注意签名方式和对应的公钥不要弄错。就支付宝来说，需要记录两个公钥，一个是与签名方式对应的应用公钥，还有一个是基于这个公钥签发的平台公钥。</p>
<p>还有一点就是支付参数中的product_code部分需要根据签约的活动来写，不能乱写。否则会一直导致参数失败的错误。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[制作一个KV编辑器]]></title>
        <id>https://xiwan.github.io/post/zhi-zuo-yi-ge-kv-bian-ji-qi</id>
        <link href="https://xiwan.github.io/post/zhi-zuo-yi-ge-kv-bian-ji-qi">
        </link>
        <updated>2019-08-28T11:12:37.000Z</updated>
        <summary type="html"><![CDATA[<p>为了后面方便快速开发自定义英雄和技能，决定开坑先做个KV编辑器。有依赖一个第三方的库来实例化KV。</p>
]]></summary>
        <content type="html"><![CDATA[<p>为了后面方便快速开发自定义英雄和技能，决定开坑先做个KV编辑器。有依赖一个第三方的库来实例化KV。</p>
<!-- more -->
<h3 id="主要功能">主要功能</h3>
<p>[系统]<br>
1. 	设置： 一些全局参数<br>
默认打开位置（英雄，技能，物品）<br>
默认文件名字（英雄，技能，物品）<br>
导入基础数据<br>
2.  关于<br>
[编辑]<br>
[英雄]<br>
1. 	导入：读取一些已经写好的KV文件<br>
2. 	新建：创建一个新的KV<br>
[技能]<br>
1. 	导入：读取一些已经写好的KV文件<br>
2. 	新建：创建一个新的KV<br>
[物品]<br>
1. 	导入：读取一些已经写好的KV文件<br>
2. 	新建：创建一个新的KV<br>
[字典]<br>
翻译官方的一些文档</p>
<h3 id="excel">excel</h3>
<p>为了快速反应基础的变化，需要一个基于excel导入的数据库。这样可以很方便地导入导出。<br>
通用的结构：</p>
<ul>
<li>ID: 主要是标识用</li>
<li>KEY: 内置KEY名字，在输入时候会进行智能匹配 (如果是#开头，表示需要从POINT范围选取)</li>
<li>GROUP: 分组用，方便展示或者其他目的</li>
<li>VALUE: 从官方搞的一些默认值</li>
<li>COMMENT: 收集的一些说明</li>
<li>PARENT: 表明KEY之间的父子关系</li>
<li>POINT: KV的取值源头（比如DOTA_ABILITY_ATTRIBUTE#DOTAUnitAttackCapability_t  表示查看比如DOTA_ABILITY_ATTRIBUTE表的DOTAUnitAttackCapability_t的分组）</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://xiwan.github.io/post-images/1567421279321.png" alt=""></figure>
<h3 id="截图">截图</h3>
<figure data-type="image" tabindex="2"><img src="https://xiwan.github.io/post-images/1566991427426.png" alt=""></figure>
]]></content>
    </entry>
</feed>
<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://xiwan.github.io</id>
    <title>Keep Thinking</title>
    <updated>2020-02-18T10:26:59.137Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://xiwan.github.io"/>
    <link rel="self" href="https://xiwan.github.io/atom.xml"/>
    <subtitle>有美人兮心不怿</subtitle>
    <logo>https://xiwan.github.io/images/avatar.png</logo>
    <icon>https://xiwan.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Keep Thinking</rights>
    <entry>
        <title type="html"><![CDATA[Redis底层协议]]></title>
        <id>https://xiwan.github.io/post/FwWrD9HpO</id>
        <link href="https://xiwan.github.io/post/FwWrD9HpO">
        </link>
        <updated>2020-02-18T09:34:39.000Z</updated>
        <summary type="html"><![CDATA[<p>最近读到官网的一篇文章 https://redis.io/topics/protocol, 主要是描述了一下redis在通讯协议。忽然觉得豁然开朗：redis作为作为一个内存数据库，其实其本质也是一个服务器而已。监听在6379（默认）接口，然后定义了一套自己的命令方便调用者使用。</p>
<p>其实市面上的主流第三方客户端都会遵守这套协议。只不过实现的语言不一样而已。这里试着分析这套协议，并且写一个简单的“redis客户端”。</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近读到官网的一篇文章 https://redis.io/topics/protocol, 主要是描述了一下redis在通讯协议。忽然觉得豁然开朗：redis作为作为一个内存数据库，其实其本质也是一个服务器而已。监听在6379（默认）接口，然后定义了一套自己的命令方便调用者使用。</p>
<p>其实市面上的主流第三方客户端都会遵守这套协议。只不过实现的语言不一样而已。这里试着分析这套协议，并且写一个简单的“redis客户端”。</p>
<!-- more -->
<h3 id="内联协议">内联协议</h3>
<p>既然是个tcp服务器，我们就可以telnet上去，类似下图这样：<br>
<img src="https://xiwan.github.io/post-images/1582019455503.png" alt=""></p>
<p>这些命令看起来和我们平时使用的差不多，不过这些命令被称为“内联命令”，而不是redis真正的通信协议。怎么理解呢？就是这些命令发过去后，redis服务器会先分析你的命令，如果发现是“内联的”，就会自己再解析成标准协议。</p>
<p>对于redis这种高性能服务器来说，花费额外的性能解析这些“内联命令”是有些得不偿失的。这里斗胆坏一下：网上有些第三方的客户端做了这种投机取巧的：）</p>
<h3 id="真正的协议">真正的协议</h3>
<p>虽然分为请求和相应两个部分，其实他们都遵循一个协议：</p>
<ul>
<li>对于<strong>简单字符串</strong>类型，它的第一个byte是&quot;+&quot;</li>
<li>对于<strong>错误</strong>类型，它的第一个byte是&quot;-&quot;</li>
<li>对于<strong>整数</strong>类型， 它的第一个byte是&quot;:&quot;</li>
<li>对于<strong>复杂字符串</strong>类型，它的第一个byte是&quot;$&quot;</li>
<li>对于<strong>数组</strong>类型，它的第一个byte是&quot;*&quot;</li>
<li><strong>结束字符</strong>固定为 &quot;\r\n&quot; (CRLF)。</li>
</ul>
<p>对于发送端：客户端永远使用<strong>数组</strong>类型，里面使用<strong>复杂字符串</strong>类型。<br>
所以举个例子，比如<em>get name</em>, 在底层就变成了</p>
<p><code>*2\r\n$3\r\nget\r\n$4\r\nname\r\n</code></p>
<p>这里做下说明： *2表示整个数组长度为2，然后\r\n都是结束字符，可以认为是redis的一种强制分隔符； $3表示get这个字符长度为3；同理, $4表示name字符长度为4。当然每个表达式中间再用CRLF字符分割即可。</p>
<p>这里我写了个简单的拼接程序：</p>
<pre><code>static readonly string CRLF = &quot;\r\n&quot;;
static string SocketCommand(string[] command) 
{
		var _len = command.Length;
		var _command = new StringBuilder();
		_command.Append($&quot;*{_len}{CRLF}&quot;);

		for (int i = 0; i &lt; _len; i++) 
		{
				_command.Append($&quot;${command[i].Length}{CRLF}{command[i]}{CRLF}&quot;);
		}

		return _command.ToString();
}
</code></pre>
<p>测试结果：</p>
<p><img src="https://xiwan.github.io/post-images/1582021232629.png" alt=""></p>
<p>可以看到和telnet模式是一样的操作，但底层协议完全不一样。</p>
<h3 id="不同的模式">不同的模式</h3>
<p>除了上面说得这种经典“一问一答”模式之外， redis还支持另外两种操作：</p>
<ol>
<li>管道技术(PIPELINE)： 当你有很多命令需要短时间执行时候，这个技术非常有用。其核心就是将多个命令打包成一个命令，减少来回的网络开销。这里有一点说明，管道和事务是有区别的，虽然他们都是合并命令。管道可以认为这些命令是松散的，中间可以插入其他的命令；而事务是相反的，这些命令是紧耦合的，必须全部执行完毕才能执行后续命令。</li>
<li>订阅模式：当客户端订阅(subscribe)某个频道后，redis将不再需要等待命令了。可以反过来在pub端发送消息，而sub端会自动获取到这些消息。这项技术在应用在我们游戏的聊天室中，还有一些跨服消息（rpc）之类。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random函数罢工了]]></title>
        <id>https://xiwan.github.io/post/POXwU3zqV</id>
        <link href="https://xiwan.github.io/post/POXwU3zqV">
        </link>
        <updated>2020-02-09T12:43:49.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="问题描述">问题描述</h3>
<p>今天下午，突然线上出现大量高级掉落重复出现。</p>
]]></summary>
        <content type="html"><![CDATA[<h3 id="问题描述">问题描述</h3>
<p>今天下午，突然线上出现大量高级掉落重复出现。</p>
<!-- more -->
<p>正常的概率是1%，结果部分玩家出现了很多。导致了群里炸了锅。于是开始分析掉落部分代码：</p>
<p><img src="https://xiwan.github.io/post-images/1581252565576.png" alt=""></p>
<p>这里做过一次优化，以前是不停的new 一个Random对象。后面测试时候发现效率不高，于是采用了复用的方式。现在似乎这里除了问题，分析下来应该是Random在某种条件下输出了相同值。</p>
<h3 id="继续分析">继续分析</h3>
<p>既然Random出了问题，那么有下面几个问题：<br>
1. 触发Random出问题的条件是什么？<br>
2. Random出问题后会输出什么值呢？<br>
3. 假如是固定值，是有条件固定还是无条件呢？</p>
<h4 id="触发条件">触发条件</h4>
<p>有一种说法是：由于不指定seed情况下，random会默认用时间的tick来当作种子。如果在一个tick内重复过多的调用，则会产生固定值。</p>
<p>不过根据线上情况分析：这个问题持续了半小时。所以这个马上被否决了。</p>
<p>接下来搜索后得到了一个线索：</p>
<p><img src="https://xiwan.github.io/post-images/1581252881498.png" alt=""></p>
<p>并且有人提到当random停止工作后，他固定返回0。</p>
<p>多线程环境下，的确使用static的random会产生这样的问题。这样来看应该是这里对于random的优化不当了。不过随之而来的是，固定值真的是0么？</p>
<h4 id="固定值">固定值</h4>
<p>停摆后的random的固定输出值是什么？真的是0。</p>
<p>同理，线上的表现否定了这个结果。因为如果是0，玩家的掉落数目也使用了这个随机数，所以他们应该获取不到这个异常的结果。。。</p>
<p>那么究竟是什么值呢？只能通过模拟多线程来压测了</p>
<p><img src="https://xiwan.github.io/post-images/1581253148318.png" alt=""></p>
<p>具体代码如上，在多线程环境下模拟随机过程，推论是：如果正常他应该输出比较均匀的分布，如果异常应该可以发现某个值特别大。</p>
<p>当次数低于100000次，我并没有看到太多异常。当超过这个值后有趣的事情发生了：</p>
<p><img src="https://xiwan.github.io/post-images/1581253310151.png" alt=""></p>
<p><img src="https://xiwan.github.io/post-images/1581253317111.png" alt=""></p>
<p><img src="https://xiwan.github.io/post-images/1581253322350.png" alt=""></p>
<p>这三次异常的结果我差不多测试了30多遍才出来。也就是说差不多只有10%的概率出现Random罢工。这样的确证实了前面的说的多线程情况下， random输出固定值。可以看到一开始应该是均匀分布的，一旦出现多线程问题，马上罢工。</p>
<h4 id="固定条件">固定条件</h4>
<p>Ranom 罢工后会输出固定值这点确认了。但不是网上大家说的是0，而是取决于我输入的min值。这样就解释了线上的大部分疑惑了。并且继续做测试可以发现，这个固定值一旦产生并不是固定不变，而是每次都等于min值。</p>
<p>测试条件为5-10，11-15两个取间同时开始随机取值，检查分布。结果如下图：</p>
<p><img src="https://xiwan.github.io/post-images/1581253614580.png" alt=""></p>
<p>看到当第一个红框出现罢工后，下一个Random值不是5，而是直接都输出成11了。</p>
<h3 id="如何改进呢">如何改进呢？</h3>
<p>原来是通过new 一个Random达到隔离的目的，但现在看来有两个问题：<br>
1. 效率不高<br>
2. 并没有根本解决多线程下罢工的问题。<br>
网上给的方案是采用锁，这样感觉效率也不高。并不能给这个底层方法带来本质的变化。</p>
<p>现在想到的一个方案类似于concurrentDictionary那样，多粒度控制锁的一个Random池子。利用这个数据结构的并发性，来创造多个可以复用的Random实例。每次需要时候采用RondRobin算法获得一个对象即可。</p>
<p>当然更激进的做法就是不用并发对象，直接做1000个实例，感觉出错的概率会下降不少。<br>
以下就是核心代码部分，每次通过到队列中获取random实例，而非反复构造它。当然在竞争十分激烈的情况下有可能拿不到random，这个时候就做了个保底。使用全局的globalRandom.</p>
<pre><code>        static Random DequeueRand(Random random)
        {
            if (random == null)
            {
                if (GlobalRandomQueue.TryDequeue(out Random rand))
                {
                    random = rand;
                    GlobalRandomQueue.Enqueue(rand);
                }
                else
                {
                    // 保底
                    random = globalRandom;
                }
            }
            return random;
        }
</code></pre>
<p>测试效果：测试10批，每批10次， 每次1百万条，random函数再也不出现“罢工“情况了</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[线上redis问题分析记录]]></title>
        <id>https://xiwan.github.io/post/9Wy-WVteG</id>
        <link href="https://xiwan.github.io/post/9Wy-WVteG">
        </link>
        <updated>2020-01-17T10:08:27.000Z</updated>
        <content type="html"><![CDATA[<p>首先祭出一般的复杂操作优化方案<br>
<img src="http://192.168.1.153/showdoc/server/../Public/Uploads/2020-01-17/5e216cc5b43ea.png" alt=""></p>
<ol>
<li>
<p>历史价格不需要拿出全部数据。看现在这部分大小不大都在1KB左右，但是由于时间长了某些物品的价格数量比较多导致list会比较长。</p>
<p><img src="http://192.168.1.153/showdoc/server/../Public/Uploads/2020-01-17/5e216d0097915.png" alt=""></p>
</li>
<li>
<p>部分玩家的事务队列是否可能出现堆积，然后队列过长？</p>
</li>
<li>
<p>寄售队列查了日志访问人数不多，将来可以考虑寄售过期之类，防止过长。</p>
</li>
<li>
<p>可以定一个大概取间让队列尽量控制在5000以内，排查下用队列比较多的地方，比如排行榜之类。</p>
</li>
<li>
<p>LDR:0:1 作为排行榜也是最热的key,需要控制大小和长度。</p>
<p><img src="http://192.168.1.153/showdoc/server/../Public/Uploads/2020-01-17/5e2177ba65644.png" alt=""></p>
</li>
<li>
<p>建议有expire的地方，如果觉得会有大量数据的前提下，都加一个随机数.像下面这种循环内设置统一过期时间的做法就有点危险</p>
</li>
</ol>
<p><img src="http://192.168.1.153/showdoc/server/../Public/Uploads/2020-01-17/5e218b722d15b.png" alt=""></p>
<ol start="7">
<li>
<p>保持主redis只放和用户相关的重要数据，周围数据都可以放在另外的redis中，需要梳理业务。</p>
</li>
<li>
<p>对于stackexchage的连接做保护</p>
</li>
<li>
<p>每日凌晨发现有集中的内存释放，并且空间还比较大.</p>
<p><img src="https://xiwan.github.io/post-images/1579255870027.png" alt=""></p>
</li>
</ol>
<p>分析完业务后发现是排行榜集中时间过期，没有做随机延迟。<br>
排行榜大的原因是没有限制数目导致的，并且还有一个安全隐患就是设置数据和expire是两条语句，有可能导致内存泄露。</p>
<pre><code>public static async Task RenewDailyStar(RaidType type, int relatedID, RaidDailyStar star)
        {
            var oldStar = RedisValue.Null;
            var key = GetDailyStarKey(type, relatedID);

            // 防止集中过期
            var expRandom = TimeSpan.FromDays(offlineExpireDay).Add(TimeSpan.FromSeconds(MathHelper.GetRandom(0, 600))); 
            try
            {
                // fetch last daily star
                var cacheStar = SerializationHelper.Serialize(star);
                // getset is atomic
                oldStar = await RedisServer.Instance().DB(dailyStarDB).StringGetSetAsync(key, cacheStar);
                if (oldStar != RedisValue.Null)
                {
                    // compare with oldstar
                    if (oldStar.Get&lt;RaidDailyStar&gt;().GetFinalScore() &gt; star.GetFinalScore())
                        await RedisServer.Instance().DB(dailyStarDB).StringSetAsync(key, oldStar, expRandom);
                }
            }
            catch (Exception ex)
            {
                LogHelper.WriteErrorLog(string.Format(&quot;{0} | {1}&quot;, star.GetFinalScore(), ex.Message));

                // 滚回操作
                if (oldStar != RedisValue.Null)
                    await RedisServer.Instance().DB(dailyStarDB).StringSetAsync(key, oldStar, expRandom);
            }
        }
</code></pre>
<ol start="10">
<li>这里是个批处理，而不是pipeline，由于取了1000位排行榜玩家数据，所以很可能这边会相当耗时。<br>
<img src="http://192.168.1.153/showdoc/server/../Public/Uploads/2020-01-17/5e217cfe86470.png" alt=""></li>
</ol>
<p>在最外层的调用地方还有一个for循环加持放大</p>
<p><img src="http://192.168.1.153/showdoc/server/../Public/Uploads/2020-01-17/5e21874521588.png" alt=""><br>
分析腾讯的监控看那个面板可以看到，每个一个小时延迟和读数目有个尖峰。应该就是这个原因导致的。</p>
<p><img src="http://192.168.1.153/showdoc/server/../Public/Uploads/2020-01-17/5e217e17cc74f.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[elk时区问题]]></title>
        <id>https://xiwan.github.io/post/zX5LGZjc5</id>
        <link href="https://xiwan.github.io/post/zX5LGZjc5">
        </link>
        <updated>2020-01-09T03:39:22.000Z</updated>
        <summary type="html"><![CDATA[<p>希望通过这篇文章能解释清楚elk中的时区问题</p>
]]></summary>
        <content type="html"><![CDATA[<p>希望通过这篇文章能解释清楚elk中的时区问题</p>
<!-- more -->
<p>由于kibana包括es默认是使用UTC时间，对于我们这种常年驻扎在东八的社畜来说十分不友好。比如我们日志是按照东八时间记录的，但到了elk中间你会发现@timestamp会莫名奇妙的少了8个小时。这是因为底层用的就是UTC。</p>
<p>于是找到一种方案是在Logstash中对齐@timestamp和日志时间：</p>
<pre><code>  ruby { 
    code =&gt; &quot;event['timestamp'] = LogStash::Timestamp.new(event['@timestamp']+ 8*60*60)&quot; 
  }
  
  ruby {
    code =&gt; &quot;event['@timestamp']= event['timestamp']&quot;
  }
</code></pre>
<p>这样做后的结果呢？</p>
<p><img src="https://xiwan.github.io/post-images/1578541551939.png" alt=""></p>
<p>由于默认设置kibana用浏览器时间，所以档这个对齐后，上午11点却只能现实凌晨3点的日志。。。感觉越搞越糟糕了。</p>
<p>仔细想下，我们其实强行同步这两个时间是有点多余的。因为kibana默认是按照@timestamp来交割，并且用的是utc时区来展示。当我们切换设置为browser，它自动将@timestamp转换到对应时区，而不影响日志展示本身。所以一旦你强行对齐这两个时间，反而会导致部分日志无法展示出来了。如果你服务器一开始就设定UTC时间来记录日志，这种对齐是没有任何问题得。但是一旦设定了其他时区，其实最好得做法就是简单的把日志时间和时区信息设置到@timestamp，剩下的就让elk自己转换即可。</p>
<pre><code>  date {
    match =&gt; [&quot;[log_json][log_datetime]&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;]
    target =&gt; &quot;@timestamp&quot;
    timezone =&gt; &quot;+08:00&quot;
  }
</code></pre>
<p>但是要记得在查询语句里面和时间相关的条件都带上timezone就好了。其实这么看来，最优雅的做法还是一开始就把服务器时间设置成UTC,可以少走很多弯路。</p>
<p>这里多说一点，elk用这个@timestamp除了展示用还有什么作用呢？索引分割用。由于我们日志是按天分割，日志文件是按小时记录。由于存在8小时时差，所以索引的一天24小时是跨了日志的两天的。比如索引7号的日志，实际是从7号早上8点到8号早上7点为止。这点明白后，在调整索引时候，最好延迟两天再做，防止对正在写入的索引产生影响。别我是怎么知道的，反正都是血泪史。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[elk的fileds被撑爆了。。。]]></title>
        <id>https://xiwan.github.io/post/WBe1HiDrr</id>
        <link href="https://xiwan.github.io/post/WBe1HiDrr">
        </link>
        <updated>2020-01-06T07:41:25.000Z</updated>
        <summary type="html"><![CDATA[<p>今天调查了一个奇怪的问题，在其他日志都是看起来的情况下，突然发现某个日志在5号凌晨开始后没有被收录了。</p>
]]></summary>
        <content type="html"><![CDATA[<p>今天调查了一个奇怪的问题，在其他日志都是看起来的情况下，突然发现某个日志在5号凌晨开始后没有被收录了。</p>
<!-- more -->
<h3 id="定位问题">定位问题</h3>
<p>通过调查日志文件本身发现是有记录的，但是没有进入elk。由于前面我已经加上了日志counter和服务器id，那么可以排除日志hash碰撞的可能性。于是开始调查logstash，得到的日志结果:</p>
<p><strong>[2020-01-06T05:47:02,707][WARN ][logstash.outputs.elasticsearch] Could not index event to Elasticsearch. {:status=&gt;400, :action=&gt;[&quot;index&quot;, {:_id=&gt;&quot;f5a3e882bfcb4f155c99db18c07093e2&quot;, :_index=&gt;&quot;kakiraid-info-2020.01.06&quot;, :_type=&gt;&quot;kakiraid_log&quot;, :_routing=&gt;nil}, #<a href="LogStash::Event:0x2ccdcf00">LogStash::Event:0x2ccdcf00</a>], :response=&gt;{&quot;index&quot;=&gt;{&quot;_index&quot;=&gt;&quot;kakiraid-info-2020.01.06&quot;, &quot;_type&quot;=&gt;&quot;kakiraid_log&quot;, &quot;_id&quot;=&gt;&quot;f5a3e882bfcb4f155c99db18c07093e2&quot;, &quot;status&quot;=&gt;400, &quot;error&quot;=&gt;{&quot;type&quot;=&gt;&quot;illegal_argument_exception&quot;, &quot;reason&quot;=&gt;&quot;Limit of total fields [1000] in index [kakiraid-info-2020.01.06] has been exceeded&quot;}}}}</strong></p>
<p>原来是索引中的字段给撑爆了。联系起前几天调整的复杂日志结构问题，是有这个可能性的。因为为了分析开卡日志和减少日志放大倍数，为每个item都动态生成了field。没想到在这里给自己挖坑了。</p>
<p>为了确定是不是这个原因，我们需要统计下当时的情况：</p>
<pre><code>curl -s -XGET http://host:port/index/_mapping? pretty | grep '&quot;type&quot;' | wc -l
</code></pre>
<p><img src="https://xiwan.github.io/post-images/1578300163529.png" alt=""></p>
<p>可以看到3号的field才741个，4号已经飙到1487个了，5号差不多1573个，6号是1463个。默认的field上线是1000个，怪不得会出现上面的错误，并且可以推断丢失的日志应该不止一种。只能说比较幸运的是，影响范围不大。</p>
<h3 id="解决问题">解决问题</h3>
<p>好吧，调整下settings。这里最重要的就是这句&quot;index.mapping.total_fields.limit&quot;: 2000(默认值是1000)。当然这里需要考虑下对于开卡这种日志，其实有必要让他自己单独享用一个index，来减少这种问题。</p>
<pre><code>{
    &quot;index.mapping.total_fields.limit&quot;: 2000,
}
</code></pre>
<p>由于一般我们会使用动态模板，这样我们每次的设置仅对当前的索引产生效果。如果第二天来的日志，还会使用默认的模板来进行索引。最好的方案是使用自定义模板:</p>
<pre><code class="language-json">put {{domain}}/_template/kakiraid-logs

{
  &quot;template&quot;: &quot;kakiraid-*&quot;, 
  &quot;order&quot;:    1, 
  &quot;settings&quot;: {
    &quot;index.indexing.slowlog.threshold.index.debug&quot; : &quot;2s&quot;,
    &quot;index.indexing.slowlog.threshold.index.info&quot; : &quot;5s&quot;,
    &quot;index.indexing.slowlog.threshold.index.trace&quot; : &quot;500ms&quot;,
    &quot;index.indexing.slowlog.threshold.index.warn&quot; : &quot;10s&quot;,
    &quot;index.mapping.total_fields.limit&quot;: 3000,
    &quot;index.merge.policy.max_merged_segment&quot; : &quot;5gb&quot;,
    &quot;index.merge.policy.segments_per_tier&quot; : &quot;24&quot;,
    &quot;index.merge.scheduler.max_merge_count&quot; : 10,
    &quot;index.merge.scheduler.max_thread_count&quot; : 1,
    &quot;index.number_of_shards&quot;: &quot;5&quot;,
    &quot;index.number_of_replicas&quot; : &quot;1&quot;,
    &quot;index.optimize_auto_generated_id&quot; : &quot;true&quot;,
    &quot;index.refresh_interval&quot; : &quot;60s&quot;,
    &quot;index.routing.allocation.total_shards_per_node&quot; : &quot;-1&quot;,
    &quot;index.search.slowlog.threshold.fetch.debug&quot; : &quot;500ms&quot;,
    &quot;index.search.slowlog.threshold.fetch.info&quot; : &quot;800ms&quot;,
    &quot;index.search.slowlog.threshold.fetch.trace&quot; : &quot;200ms&quot;,
    &quot;index.search.slowlog.threshold.fetch.warn&quot; : &quot;1s&quot;,
    &quot;index.search.slowlog.threshold.query.debug&quot; : &quot;2s&quot;,
    &quot;index.search.slowlog.threshold.query.info&quot; : &quot;5s&quot;,
    &quot;index.search.slowlog.threshold.query.trace&quot; : &quot;500ms&quot;,
    &quot;index.search.slowlog.threshold.query.warn&quot; : &quot;10s&quot;,
    &quot;index.translog.durability&quot; : &quot;async&quot;,
    &quot;index.translog.flush_threshold_size&quot; : &quot;5000mb&quot;,
    &quot;index.translog.sync_interval&quot;: &quot;600s&quot;,
	&quot;index.unassigned.node_left.delayed_timeout&quot; : &quot;7200m&quot;
  },
  &quot;mappings&quot;: {
    &quot;_default_&quot;: { 
	  &quot;dynamic&quot;: true,
      &quot;_all&quot;: {
        &quot;enabled&quot;: false
      },
      &quot;dynamic_templates&quot;: [
        {
          &quot;string_template&quot;: {
            &quot;match_mapping_type&quot;: &quot;string&quot;,  
            &quot;match&quot;: &quot;*&quot;,                    
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;text&quot;,
              &quot;fields&quot;: {
                    &quot;keyword&quot;: {
                        &quot;type&quot;: &quot;keyword&quot;,
                        &quot;ignore_above&quot;: 256
                    }
                }
            }
          }
        },
        {
          &quot;ip&quot;: {
            &quot;match_mapping_type&quot;: &quot;*&quot;,
            &quot;match&quot;: &quot;*_ip&quot;,
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;ip&quot;
            }
          }
        },
        {
          &quot;date&quot;: {
            &quot;match&quot;: &quot;*_date&quot;,            
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;date&quot;,            
              &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;  
            }
          }
        },
        {
          &quot;keyword&quot;: {
            &quot;match_mapping_type&quot;: &quot;string&quot;,
            &quot;match&quot;: &quot;*_k&quot;,                 
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;keyword&quot;,
              &quot;ignore_above&quot;: 256,
              &quot;null_value&quot;: &quot;null&quot;
            }
          }
        },
        {
          &quot;long&quot;: {
            &quot;match_mapping_type&quot;: &quot;*&quot;,
            &quot;match&quot;: &quot;*_l&quot;,              
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;integer&quot;          
            }
          }
        },
        {
          &quot;double&quot;: {
            &quot;match_mapping_type&quot;: &quot;*&quot;,
            &quot;match&quot;: &quot;*_d&quot;,              
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;double&quot;           
            }
          }
        },
        {
          &quot;boolean&quot;: {
            &quot;match_mapping_type&quot;: &quot;boolean&quot;,
            &quot;match&quot;: &quot;*_b&quot;,                
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;boolean&quot;
            }
          }
        },
        {
          &quot;analyzer&quot;: {
            &quot;match&quot;: &quot;*_a&quot;,                
            &quot;mapping&quot;: {
              &quot;type&quot;: &quot;text&quot;,                
              &quot;index&quot;: true,
              &quot;analyzer&quot;: &quot;english&quot;,        
              &quot;null_value&quot;: &quot;null&quot;
            }
          }
        }
      ]
    }
  }
}
</code></pre>
<p>其他的是我为了加快索引速度给的一些“调优”。比如refresh_interval这个默认值是1s，虽然看上去日志是所见即所得，但有的时候并不需要这么快。可以适当的延长这个值，让日志在file_cache中多呆一会儿再被可见。其实对于elk来说，文档可见其实只要缓存到了file_cache中即可，并不需要写入到硬盘。</p>
<p>当然通过flush也是可以保证这点的，但是它的代价就是磁盘io。所以我这里将translog设定成了异步并且有大小阈值的。因为这些日志文件并不是那么的重要。</p>
<p>同时我还设定了dynamic_templates来保证未来的扩展性，只要符合命名规则就可以自动解析成想要的类型了。这里要注意得是模板其实也有顺序的，个人越是通用的应该要放在上面比较好。然后对于string类型来说，建议还是使用text而不是keyword，这样会使得日常查看日志方便许多。</p>
<h3 id="如何重新装载日志呢">如何重新装载日志呢？</h3>
<p>为了保证日志的完整性，肯定是需要重新index受到影响的日志。这个结合filebeat的inode特性，我们首先需要隔离开受到“错误”影响的日志，比如某个时间段之后的日志的索引都有问题。按照我的经验是截至到当天的前一天为好。最重要的原因是当天的index还没有完成，处于正在执行状态，是不会接受已经被索引过的日志的。要么就是停止当天的索引，要么就是隔天操作。</p>
<p>隔离开的日志只要更换下inode，然后就可以做到不停机的情况下重新index了。比较稳妥的方案是可以删除掉已经存在Index, 然后找一个压力比较小的时候做以上的操作:)</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[logstash 如何处理复杂日志]]></title>
        <id>https://xiwan.github.io/post/6SadtR1zT</id>
        <link href="https://xiwan.github.io/post/6SadtR1zT">
        </link>
        <updated>2019-12-26T10:30:44.000Z</updated>
        <summary type="html"><![CDATA[<p>最近压测发现日志在抽奖接口会放大百倍，直接把10万长度的日志队列挤爆！</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近压测发现日志在抽奖接口会放大百倍，直接把10万长度的日志队列挤爆！</p>
<!-- more -->
<p>深入调查后发现，抽奖接口的逻辑是得到一个物品就会对应一条日志。然后经常用户会大量开卡包的情况下，会单次获得许多物品，这样照成了日志的放大。压测时候每次请求会产生261条日志！！！</p>
<p>第一个想到的解决方案是日志合并，在抽奖的最后再写一条日志。不过这带来新的挑战，日志的维度会增加。导致现阶段的分析方式都无法使用了。</p>
<p>举例来说，对于这样一条日志，它是以分隔符竖线来区别每个字段意思的：</p>
<pre><code>2019-12-24 23:59:59|9|116504|76561198271728609@STEAM|4|86|9|127|32|-1|4||10011|1462231
</code></pre>
<p>这样我们在logstash里面处理时候简单的split结果，然后按照位置即可获得字段的意思。一次抽卡有可能产生多条这样的日志，所以上面的处理方案就会合并成</p>
<pre><code>2019-12-26 17:11:29|9|10001889532|bot1234567890|0|16|1617,87|1504^1,1551^1,1536^1,1539^1,1511^1,1503^1,1533^1,1552^1,1535^1,1504^1,1505^1,1528^1,1542^1,1519^1,1533^1,1525^1,1502^1,1503^1,1503^1,1502^1,1534^1,1545^1,1502^1,1502^1,1502^1,1505^1,1526^1,1510^1,1503^1,1549^1,1531^1,1509^1,1501^1,1526^1,1551^1,1501^1,1530^1,1504^1,1551^1,1548^1,1513^1,1521^1,1554^1,1511^1,1526^1,1551^1,1508^1,1529^1,1514^1,1516^1,1536^1,1526^1,1528^1,1554^1,1526^1,1551^1,1524^1,1541^1,1536^1,1502^1,1539^1,1549^1,1505^1,1511^1,1504^1,1539^1,1501^1,1501^1,1529^1,1529^1,1503^1,1551^1,1509^1,1519^1,1541^1,1528^1,1514^1,1507^1,1548^1,1512^1,1534^1,1523^1,1501^1,1501^1,1503^1,1534^1,1538^1,1529^1,1505^1,1517^1,1531^1,1536^1,1505^1,1539^1,1547^1,1504^1,1540^1,1504^1,1551^1,1535^1,1505^1,1519^1,1518^1,1504^1,1526^1,1525^1,1504^1,1501^1,1550^1,1542^1,1529^1,1554^1,1509^1,1552^1,1554^1,1512^1,1501^1,1521^1,1515^1,1525^1,1535^1,1552^1,1510^1,1527^1,1507^1,1523^1,1516^1,1513^1,1538^1,1551^1,1502^1,1536^1,1501^1,1506^1,1533^1,1543^1,1527^1,1539^1,1521^1,1513^1,1540^1,1504^1,1503^1,1530^1,1549^1,1552^1,1545^1,1553^1,1501^1,1536^1,1533^1,1551^1,1511^1,1502^1,1502^1,1529^1,1536^1,1549^1,1508^1,1552^1,1503^1,1533^1,1540^1,1512^1,1524^1,1501^1,1541^1,1536^1,1505^1,1503^1,1528^1,1523^1,1551^1,1513^1,1504^1,1527^1,1539^1,1512^1,1551^1,1550^1,1552^1,1507^1,1528^1,1536^1,1552^1,1505^1,1552^1,1548^1,1530^1,1536^1,1523^1,1509^1,1541^1,1503^1,1503^1,1533^1,1505^1,1505^1,1508^1,1501^1,1535^1,1543^1,1508^1,1523^1,1536^1,1514^1,1542^1,1547^1,1505^1,1504^1,1539^1,1503^1,1503^1,1502^1,1551^1,1525^1,1545^1,1516^1,1522^1,1543^1,1552^1,1501^1,1503^1,1504^1,1532^1,1531^1,1505^1,1518^1,1536^1,1552^1,1501^1,1551^1,1509^1,1535^1,1520^1,1511^1,1539^1,1523^1,1514^1,1504^1,1546^1,1515^1,1504^1,1527^1,1529^1,1524^1,1547^1,1534^1,1548^1,1525^1,1501^1,1552^1,1547^1,1548^1,1527^1,1501^1,1551^1,1546^1,1504^1,1552^1,1547^1||10021|199
</code></pre>
<p>对的，你没看错也没有搞错！一下子日志维度就上去了。</p>
<h3 id="改造logstash">改造logstash</h3>
<p>由于单纯的写logstash的split似乎无法完成上面的任务了（主要问题是不定长array处理起来十分麻烦），所以我对准了它的ruby插件:</p>
<pre><code>ruby {
        code =&gt; '
          item_array=event.get(&quot;[log_json][t9_item_id]&quot;).split(&quot;,&quot;)
          event.set(&quot;[log_json][t9_item_length]&quot;, item_array.length)
          for item in item_array
            value=event.get(&quot;[log_json][t9_item_#{item.split(&quot;^&quot;)[0]}]&quot;)
            if value.nil?
              event.set(&quot;[log_json][t9_item_#{item.split(&quot;^&quot;)[0]}]&quot;, item.split(&quot;^&quot;)[1].to_i)
            elsif
              event.set(&quot;[log_json][t9_item_#{item.split(&quot;^&quot;)[0]}]&quot;, item.split(&quot;^&quot;)[1].to_i+value.to_i)
            end
          end
        '
      }
</code></pre>
<p>可以看到在ruby内部, 每一条日志其实是一个event. 通过内置的event.set 和 get方法就可以很简单的将日志继续分割下去。</p>
<p>最后得到的结果为：</p>
<p><img src="https://xiwan.github.io/post-images/1577357078972.png" alt=""></p>
<p>当然我们也关系加入新的ruby插件后的效率问题。找了台4G，2核的普通机器在没有调优参数的情况下，pv 压测后的结果为:</p>
<p>4核4GB的机器结果** 978KiB 0:05:43 [2.85KiB/s]**差不多100万条复杂数据，每秒2.85k个event的速度</p>
<p>这里有个比较有意思的收获，原来获取array的尾部在conf里面可以写-1...</p>
<h3 id="elk查询">elk查询</h3>
<p>上面基本解决了logstash在多维度结构时候的解析问题，对于elk中一个按照物品id的聚合查询该如何做呢？</p>
<p>我想的思路是： 传入item_id, 匹配日志name, 由于value是记录了数目，那么query里面的条件则是Numeric Range Query Usage来进行比较（大于0即可）。在aggregator里面的则是用总和sum操作即可。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis 大key处理]]></title>
        <id>https://xiwan.github.io/post/b0uwzUXQ8</id>
        <link href="https://xiwan.github.io/post/b0uwzUXQ8">
        </link>
        <updated>2019-12-16T04:38:38.000Z</updated>
        <summary type="html"><![CDATA[<p>最近压测登陆接口，发现处理超过1k的byte对象（我们初始化就有3k,跑起来后可以达到40k）时候，整体的tqs下降得十分厉害。从一般几千得并发掉落倒了不到一千，还有不少得错误。</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近压测登陆接口，发现处理超过1k的byte对象（我们初始化就有3k,跑起来后可以达到40k）时候，整体的tqs下降得十分厉害。从一般几千得并发掉落倒了不到一千，还有不少得错误。</p>
<!-- more -->
<p><img src="https://xiwan.github.io/post-images/1576471294178.png" alt=""></p>
<p>经过调查这个应该是redis在处理大key时候的一个坑，每次的全量更新让单线程的redis十分缓慢，无法在规定时间内完成操作。</p>
<h2 id="解决办法">解决办法</h2>
<p>对于大key,网上查了下给了两种解决方案：</p>
<pre><code>1. 改成hash格式，每次更新hash的一个部分
2. 将大key改成多个小key的组合，使用multiSet,或者multiGet来完成业务。
</code></pre>
<p>这两种方案其实大同小异，但比较不爽的是需要对业务部分进行从新梳理。这样才可以控制每个部分的大小。改造方案其实是十分昂贵的。如果不是一开始就有考虑这个部分，其实不建议这么操作。</p>
<p>对于redis的key-value模型，value其实作为stream存储的话，我们可以采用一种另存整取的思路来做。比如每次我按照200Byte存一次，对于一个1KB的数据，我们需要存5条记录就可以了。相应的，在我们需要读取时候，我们把对应key所有的相关的key数据按照一定顺序还原就可以恢复成原来的对象了。</p>
<h3 id="零存方案">零存方案</h3>
<pre><code>        public async Task SegmentWrite(string key, byte[] data)
        {
            IByteBuffer bytesBuffer = Unpooled.Buffer(data.Length);
            try
            {
                // 加锁
                if (!await Lock(key))
                {
                    throw new Exception(&quot;Lock-fail &quot; + key);
                }

                IBatch batch = DB().CreateBatch();
                bytesBuffer.WriteBytes(data);
                int j = 0;
                while (bytesBuffer.ReadableBytes &gt; 0)
                {
                    var ReadableBytes = Math.Min(segmentLength, bytesBuffer.ReadableBytes);
                    var segKey = key + &quot;-&quot; + j++;
                    //await batch.StringAppendAsync(segKey, bytesBuffer.ReadBytes(ReadableBytes).Array, flags: CommandFlags.FireAndForget);
                    await batch.StringSetAsync(segKey, bytesBuffer.ReadBytes(ReadableBytes).Array, flags: CommandFlags.FireAndForget);
                }
                if (j&gt;0)
                    batch.Execute();

            }
            catch (Exception ex)
            {
                Console.WriteLine(ex.Message);
            }
            finally
            {
                bytesBuffer.Release();
                data = null;
                if (!await Unlock(key))
                {
                    throw new Exception(&quot;Unlock-fail&quot;);
                }
            }
        }
</code></pre>
<h4 id="整取方案">整取方案</h4>
<pre><code>        public async Task&lt;T&gt; SegmentRead&lt;T&gt;(String key)
        {
            IByteBuffer bytesBuffer = Unpooled.Buffer(segmentLength);
            try
            {
                if (!await Lock(key))
                {
                    throw new Exception(&quot;Lock-fail &quot; + key);
                }
                RedisResult keysResult = await DB().ExecuteAsync(&quot;keys&quot;, key + &quot;-*&quot;);
                if (keysResult.IsNull) {
                    return default;
                }
                RedisResult[] keyList = (RedisResult[])keysResult;

                List&lt;Task&gt; ayncTaskList = new List&lt;Task&gt;();
                foreach (var _key in keyList.OrderBy(k =&gt; Encoding.Default.GetString((byte[])k)).ToArray())
                {
                    var keystr = Encoding.Default.GetString((byte[])_key);
                    bytesBuffer.WriteBytes(await DB().StringGetAsync(keystr));
                }
                return bytesBuffer.ReadableBytes &gt; 0 ? bytesBuffer.ReadBytes(bytesBuffer.ReadableBytes).Array.Deserialize&lt;T&gt;() : default;
            }
            catch (Exception ex)
            {
                Console.WriteLine(ex.Message);
                return default;
            }
            finally
            {
                bytesBuffer.Release();
                if (!await Unlock(key))
                {
                    throw new Exception(&quot;Unlock-fail&quot;);
                }

            }

        }
</code></pre>
<h3 id="注意事项">注意事项</h3>
<ol>
<li>由于对于大key单次的写入和读取操作都被分割成了小块，所以redis的原子操作已经被破坏。所以我们每次写之前对于同一个key要加锁，写完之后再释放锁。同理，在读的时候也要检查是否有写的锁，如果某个进程正在写入同一个key，则需要等待。</li>
<li>等待不能无止境的持续下去，要做好保护，防止程序卡死。</li>
<li>对于切割出来的基本单元可以采用pipeline写入方式保证效率</li>
<li>读取key的时候一定要做好排序，保证结果的正确性。</li>
<li>不能将基本单元切割得过小，产生的key过多也会成为性能瓶颈。</li>
<li>减少内存拷贝</li>
</ol>
<h3 id="测试结果">测试结果</h3>
<p>在500B为一个基本单元情况下的测试结果。可以看到错误率明显下降，整体的tqs也上升了20%左右。<br>
<img src="https://xiwan.github.io/post-images/1576472238470.png" alt=""></p>
<p>观察了下elk的做法，它也会将index拆分成5个shard，然后做一份replica，再散列在集群里面。这么做的好处是可以减少某个热key引起的请求偏移；当然也不需要再关注上层的业务逻辑了。这应该是一个比较主流的做法：</p>
<p><img src="https://xiwan.github.io/post-images/1577268824992.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[filebeat踩坑inode]]></title>
        <id>https://xiwan.github.io/post/filebeat踩坑inode</id>
        <link href="https://xiwan.github.io/post/filebeat踩坑inode">
        </link>
        <updated>2019-11-18T07:39:13.000Z</updated>
        <summary type="html"><![CDATA[<p>最近我们游戏调整了服务器架构，所以涉及到一些文件系统的改动。类似于文件重命名之类。按照之前的理解这种操作在停服时候做，通过脚本应该是比较安全快捷的。不过正式由于这个操作，让我花了一个通宵才查明一个filebeat的问题。</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近我们游戏调整了服务器架构，所以涉及到一些文件系统的改动。类似于文件重命名之类。按照之前的理解这种操作在停服时候做，通过脚本应该是比较安全快捷的。不过正式由于这个操作，让我花了一个通宵才查明一个filebeat的问题。</p>
<!-- more -->
<h2 id="表现">表现</h2>
<p>说到具体表现就是重启服务器后，发现ELK收集日志部分Load十分高。排查下来发现filebeat重新在收集已经收集过的日志。对于日志量少的服务器这个变化应该是很难察觉的。但不巧的是，我们玩家服务器已经积累了几亿的日志，集群的速度估计3kw-5kw之间。这么算下来，我们至少有一个礼拜没法看日志了。</p>
<p>反复检查完配置，也确认了registery没有被误删除的情况下，怎么filebeat会突然抽风。不认识已经收集过的日志了？思来想去，只能硬着头皮查Registry相关信息：</p>
<h3 id="registry文件">Registry文件</h3>
<p>Filebeat会将自己处理日志文件的进度信息写入到registry文件中，以保证filebeat在重启之后能够接着处理未处理过的数据，而无需从头开始</p>
<p>registry文件内容为一个list，list里的每个元素都是一个字典，字典的格式如下：</p>
<pre><code>source： 记录采集日志的完整路径
offset： 采集这个日志文件到了哪个位置，总采集字节数
inode： 日志文件的inode号，关于inode的详细解释看下文
device： 日志所在的磁盘编号，下文stat命令中Device的值
timestamp： 日志最后一次发生变化的时间戳
ttl： 采集失效时间，-1表示永不失效
</code></pre>
<p>Filebeat在每次启动时都会来读取这个文件，如果文件不存在则会创建新文件。</p>
<h3 id="inode解释">inode解释</h3>
<p>那么Filebeat是怎么判断一个文件是否认识呢？原来它是基于inode这个字段。可以说这个是linux文件系统的一个比较核心的东西。它这个结构体定义了一系列文件的元信息，比如文件的创建者、创建时间、文件大小等等。每个文件都对应了它，一般可以用 <strong>stat</strong> 命令查看。</p>
<p>简单理解就是在linux中，同一个文件的判断条件就是inode值是否相等。如果要快速查看inode，可以用 <strong>ls -i</strong>命令看到这里，我有了一个推断：这次调整结构为了脚本的方便调整了日志的路径。但是具体的脚本是用cp方式建立的。cp方式虽然会让文件的内容和名字一致，但是会去重新申请inode值。当然如果系统的inode值耗尽了，尽管还有磁盘空间，也会导致无法建立新的文件。如果要保持inode不变，需要用的是mv方式或者ln（硬链接，不是软连接）方式，并且不能跨磁盘（区）。</p>
<h2 id="验证">验证</h2>
<p>估计filebeat底层也是沿用的这一套。为了验证我的猜想，于是做了下面的实验：</p>
<p><img src="https://xiwan.github.io/post-images/1574064453379.png" alt=""></p>
<p>可以看到同一个文件通过cp方式，inode值的确变化了。相应的我们用mv方式就不会有影响：</p>
<p><img src="https://xiwan.github.io/post-images/1574064532919.png" alt=""></p>
<p>网上也查到filebeat的文件说明：</p>
<p><img src="https://xiwan.github.io/post-images/1574064603448.png" alt=""></p>
<h2 id="解决">解决</h2>
<p>到这里，自然解决方案也出来了</p>
<pre><code>1. 写脚本用mv的方式来移动老的日志文件
2. 不要随意改变既定的文件结构
</code></pre>
<p>操作完之后，果然filebeat又重新识别出来老的日志文件了。整个elk的压力也下去了。回过头看这一次踩坑：感觉linux底层还是值得好好研究下的。写写脚本简单，但也只是知其然不知其所以然。对于cp，mv, rm这类常用命令的理解也深刻了不少。自己操作或者指导别人时候也会特别小心了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[写代码的一点思考]]></title>
        <id>https://xiwan.github.io/post/写代码的一点思考</id>
        <link href="https://xiwan.github.io/post/写代码的一点思考">
        </link>
        <updated>2019-11-07T04:22:58.000Z</updated>
        <summary type="html"><![CDATA[<p>专门用来总结一些经验和想法，不一定正确</p>
]]></summary>
        <content type="html"><![CDATA[<p>专门用来总结一些经验和想法，不一定正确</p>
<!-- more -->
<h2 id="利用反射和泛型快速创造一个对象">利用反射和泛型快速创造一个对象</h2>
<p>这里可以看到一个Single类的写法<br>
<img src="https://xiwan.github.io/post-images/1573101268759.png" alt=""></p>
<p>那么当我们需要让另外一个类成为单例时候就可以很简单的继承它即可</p>
<pre><code>    public class Director : Single&lt;Director&gt;
</code></pre>
<p>这个写法只是适合部分场景，对于对于常用的Helper类，其实直接用static类就可以了。</p>
<h2 id="通过多重继承来继承多个类">通过多重继承来继承多个类</h2>
<p>一般来说单个类都是无法一次性继承多个类的，但是我们可以让这类之间行成父子关系。这样最终的儿子类是可以拥有所有先辈的公共成员的。</p>
<p>我们创建了一个抽象类继承了Single，则它拥有了单例的特性</p>
<pre><code>    public abstract class SheetObj&lt;T, V&gt; : Single&lt;T&gt; 
        where T: class where V : ExtendObj
</code></pre>
<p>然后又创建了三个子类继承了SheetObj</p>
<pre><code>    public class EnumBook : SheetObj&lt;EnumBook, Enum&gt;
    public class RangeBook : SheetObj&lt;RangeBook, Range&gt;
    public class EnumBook : SheetObj&lt;EnumBook, Enum&gt;
</code></pre>
<p>那么我们在使用这些子类时候就可以这么用：</p>
<pre><code>// Single类的初始化方法
    RangeBook.Initialize();
    EnumBook.Initialize();
    TreeBook.Initialize();
// SheetObj的加载数据方法
    RangeBook.Instance.Load(MasterDataFilePath);
    EnumBook.Instance.Load(MasterDataFilePath);
    TreeBook.Instance.Load(MasterDataFilePath);
</code></pre>
<p>实际上使用时候还可以考虑抽象函数，虚函数或者协议接口之类来满足自己的需求。</p>
<h2 id="抽取共同的成员到基类">抽取共同的成员到基类</h2>
<p>比如类A,B,C都有一个成员变量为ID，那么就可以先做一个基类，其余的类可以通过继承方式获取到这个成员变量。当然，这个思路可以扩展开来，会让类的结构有些复杂。但是能节省很多重复劳动工作。<br>
不过有些项目不在乎这些重复，希望简单直白的类来节约debug时间。所以真正如何使用还是需要权衡。</p>
<p>不过现在很多代码插件都有一键生成各种set, get方法。甚至还有比较邪门的lombook这类东西。底层似乎是用了动态类的机制。在这里就不展开了。</p>
<h2 id="覆盖object的tostring方法">覆盖object的ToString()方法</h2>
<p>在基类中重写ToString()方法，这样可以在Debug问题时候十分方便的查看对象的具体数据。</p>
<p><img src="https://xiwan.github.io/post-images/1573102105886.png" alt=""></p>
<h2 id="善用builder模式">善用Builder模式</h2>
<p>经常写代码时候会碰到要创建一个对象块，由于成员变量过多，会导致代码块十分臃肿。这个时候可以用Builder模式来改造类。</p>
<p><img src="https://xiwan.github.io/post-images/1573102260623.png" alt=""></p>
<p>上图这个列子中p1和p2就是很好解释了前面的观点。<br>
p2是一种普通的生成类的方式，十分简单直白，但不好的是业务逻辑和生命混杂在一起十分乱。p1比较起来就会显得简单很多。</p>
<p>通常的思路是创建一个Builder类专门负责生成目标对象。这么做的好处主要是如下考虑<br>
1. 在生成对象的地方代码会十分简洁，配合链式声明，整个代码的可读性也会很好。<br>
2. 解耦了对象生成和具体的业务逻辑，对调用者保持透明性。</p>
<p>不过正如第二点说明那样，业务逻辑被挪到了Builder里面去做了，这并不会少写不少代码。不过就我个人来说，目前还是比较值的。</p>
<p><img src="https://xiwan.github.io/post-images/1573102774966.png" alt=""></p>
<h2 id="builder继续优化">Builder继续优化</h2>
<p>通过观察发现这些设置成员变量的方法似乎都是差不多模式：通过一个key算出一个值，然后赋予成员便令，最后返回Builder本身。这样我们可以使用delegate模式，把这个部分的逻辑通过方法参数传入进来。</p>
<p><img src="https://xiwan.github.io/post-images/1573114364942.png" alt=""></p>
<p>这样我们的Builder就会变得十分轻量了，前面所有的赋值操作以及返回都变作了一个delegate函数：</p>
<p><img src="https://xiwan.github.io/post-images/1573114497904.png" alt=""></p>
<p>这样我们使用Builder生成对象也有相应变化：</p>
<p><img src="https://xiwan.github.io/post-images/1573114673344.png" alt=""></p>
<p>如上图所示，我们发现p3和p1比较起来似乎更加复杂了，也不如p2直观。 其实这一来一去，我们从p2模式到p1主要是为了解决代码块比较笨重的问题，扩展性也差。但是新的问题是业务逻辑被隐藏到了Builder里面。其实仔细想想，对于Builder来说它并不需要关心你业务逻辑是怎样的，它唯一要做的就是把某个业务逻辑（规则）产生的结果赋予给相应的值就好了。基于这个考虑，我们也要把业务逻辑解耦开来。所以通过delegate这种方式，很好地做到了这点。整个builder赋值时候做地也是最存粹地操作而已！</p>
<p>p3的做法把这也业务规则包装成方法后，可以写一个专门地处理业务逻辑类，它负责封装各种业务算法然后输出而已。同样也保持了简单高效的模式。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[steam真的挂了2小时]]></title>
        <id>https://xiwan.github.io/post/steam真的挂了2小时</id>
        <link href="https://xiwan.github.io/post/steam真的挂了2小时">
        </link>
        <updated>2019-10-29T07:30:59.000Z</updated>
        <content type="html"><![CDATA[<p>早上一起来被告知昨晚有将近两个小时的游戏服务器连接失败。大概的样子是这样：</p>
<p><img src="https://xiwan.github.io/post-images/1572334369507.png" alt=""></p>
<p>第一排查的是机房网络情况，经过询问得知网络正常。然后开始分析日志，发现如下特点：</p>
<ol>
<li>连接失败的开始时间和结束时间差不多（夜里2点-4点）</li>
<li>两个机房都出现了上面的情况（国内，国外）</li>
</ol>
<p>根据以上两条进一步分析，机房的网络问题被排除了。</p>
<p>排除掉机房后，我又看了下当时的cpu内存情况也没有异常。接下来只能重新掉头分析上报内容了，感觉大部分失败都是在登陆界面。游戏内玩家报告失败的情况没有。这个时候反应是不是steam平台炸了。但是这个怎么验证呢？这么大的平台炸了，为啥网上没有一点消息。。。</p>
<p>接着只能硬着头皮查日志了</p>
<p><img src="https://xiwan.github.io/post-images/1572334817578.png" alt=""></p>
<p>根据日志这段时间分析也发现了几个特点：</p>
<pre><code>1. 两个机房出现情况的时间点不单单是差不多，而是精确到秒级别的同步。
2. 一般的超时差不多就是几百毫秒，这段时间的超时居然高达了100秒。
</code></pre>
<p>根据1来推断有两种可能性。第一种是我们又被攻击了，不过我很快否定了这个想法。因为攻击不可能挑选半夜人少时候，并且只持续了2小时左右就停止了，这个不大符合规律。那么就是最不可能的肯能了：steam平台昨晚挂了。</p>
<p>steam平台有波动是很正常，但2个小时的时间算是一个不小的事故了。会不会是因为某次波动导致的底层bug，从而请求阻塞之类？不过经过老板提点，还是否定了这个思路，因为两个机房，相同的时间节点。由于两边环境的差异，不可能这么凑巧的。所以真相只有一个：steam 挂了2小时。</p>
<p>顺着这个思路，我终于找到了一个作证：</p>
<p><img src="https://xiwan.github.io/post-images/1572335271678.png" alt=""></p>
<p>相关网站 https://outage.report/steam 。这个是一个专门给玩家们上报steam 挂机了的网站。报告的热点图几乎都在北美和欧洲，国内似乎知道的人很少，并且由于出问题时间在半夜，所以并没有人会怀疑到steam上面去。</p>
<p>这下一切就解释得通了：steam昨晚真得挂了2个小时！根据宕机历史来看，steam不算太靠谱。。。</p>
<h2 id="隐患">隐患</h2>
<p>当解决完上面的疑惑后，还有一个问题：为啥steam宕机时候我们居然挂机了100秒？幸亏这个问题是半夜发生，如果是高峰期，可能直接导致游戏内玩家都会无法使用。这也算是一个比较大的隐患了。当然，最后解决这个问题是比较简单，重新设置下timeout和readwritetimeout时间就好了。</p>
<p>对于request里面给的解释：</p>
<pre><code>timeout 相当于请求发出到建立连接所花费的时间，默认100秒
readwritetimeout 相当于建立连接到下载完整个包体需要的时间，默认300秒
</code></pre>
]]></content>
    </entry>
</feed>